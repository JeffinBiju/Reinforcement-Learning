{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRofzaCc8rKP"
   },
   "source": [
    "## DQN and Actor Critic Methods \n",
    "\n",
    "### Jeffin Biju (EE19B085) and Rajdeep Paul (EE19109)\n",
    "\n",
    "Contains DQN, one step, n step and full returns Actor Critic Methods for CartPole-v1, Acrobot-v1, MoutainCar-v0.\n",
    "\n",
    "Code for one step method is different from code for n step and full returns since one step in implemented in an online fashion where updates are made at every time step while n step and full return updates are made at the end of the episode. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xNf714h85dX"
   },
   "source": [
    "### DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TQG6NIB3ETK"
   },
   "source": [
    "#Mountain Car\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7C5Loo2Uk4ch"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, size, input_shape):\n",
    "        self.size = size\n",
    "        self.counter = 0\n",
    "        self.state_buffer = np.zeros((self.size, input_shape), dtype=np.float32)\n",
    "        self.action_buffer = np.zeros(self.size, dtype=np.int32)\n",
    "        self.reward_buffer = np.zeros(self.size, dtype=np.float32)\n",
    "        self.new_state_buffer = np.zeros((self.size, input_shape), dtype=np.float32)\n",
    "        self.terminal_buffer = np.zeros(self.size, dtype=np.bool_)\n",
    "\n",
    "    def store_tuples(self, state, action, reward, new_state, done):\n",
    "        idx = self.counter % self.size\n",
    "        self.state_buffer[idx] = state\n",
    "        self.action_buffer[idx] = action\n",
    "        self.reward_buffer[idx] = reward\n",
    "        self.new_state_buffer[idx] = new_state\n",
    "        self.terminal_buffer[idx] = done\n",
    "        self.counter += 1\n",
    "\n",
    "    def sample_buffer(self, batch_size):\n",
    "        max_buffer = min(self.counter, self.size)\n",
    "        batch = np.random.choice(max_buffer, batch_size, replace=False)\n",
    "        state_batch = self.state_buffer[batch]\n",
    "        action_batch = self.action_buffer[batch]\n",
    "        reward_batch = self.reward_buffer[batch]\n",
    "        new_state_batch = self.new_state_buffer[batch]\n",
    "        done_batch = self.terminal_buffer[batch]\n",
    "\n",
    "        return state_batch, action_batch, reward_batch, new_state_batch, done_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kg3muRr7SsAf",
    "outputId": "c42c9f91-099a-4ed9-e84b-caf55c84c2cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# change path here as per your directory structure\n",
    "os.chdir('drive/My Drive/CS6700/PA2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DodDXGBEioFX"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def DeepQNetwork(lr, num_actions, input_dims, fc1, fc2):\n",
    "    q_net = Sequential()\n",
    "    q_net.add(Dense(fc1, input_dim=input_dims, activation='relu'))\n",
    "    q_net.add(Dense(fc2, activation='relu'))\n",
    "    q_net.add(Dense(num_actions, activation=None))\n",
    "    q_net.compile(optimizer=Adam(learning_rate=lr), loss='mse')\n",
    "\n",
    "    return q_net\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, lr, discount_factor, num_actions, epsilon, batch_size, input_dims):\n",
    "        self.action_space = [i for i in range(num_actions)]\n",
    "        self.discount_factor = discount_factor\n",
    "        self.epsilon = epsilon\n",
    "        self.batch_size = batch_size\n",
    "        self.epsilon_decay = 0.0001\n",
    "        self.epsilon_final = 0.01\n",
    "        self.update_rate = 40\n",
    "        self.step_counter = 0\n",
    "        self.buffer = ReplayBuffer(300000, input_dims)\n",
    "        self.q_net = DeepQNetwork(lr, num_actions, input_dims, 256, 256)\n",
    "        self.q_target_net = DeepQNetwork(lr, num_actions, input_dims, 256, 256)\n",
    "\n",
    "    def store_tuple(self, state, action, reward, new_state, done):\n",
    "        self.buffer.store_tuples(state, action, reward, new_state, done)\n",
    "\n",
    "    def policy(self, observation):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            state = np.array([observation])\n",
    "            actions = self.q_net(state)\n",
    "            action = tf.math.argmax(actions, axis=1).numpy()[0]\n",
    "\n",
    "        return action\n",
    "\n",
    "    def train(self):\n",
    "        if self.buffer.counter < self.batch_size:\n",
    "            return\n",
    "        if self.step_counter % self.update_rate == 0:\n",
    "            self.q_target_net.set_weights(self.q_net.get_weights())\n",
    "\n",
    "        state_batch, action_batch, reward_batch, new_state_batch, done_batch = \\\n",
    "            self.buffer.sample_buffer(self.batch_size)\n",
    "\n",
    "        q_predicted = self.q_net(state_batch)\n",
    "        q_next = self.q_target_net(new_state_batch)\n",
    "        q_max_next = tf.math.reduce_max(q_next, axis=1, keepdims=True).numpy()\n",
    "        q_target = np.copy(q_predicted)\n",
    "\n",
    "        for idx in range(done_batch.shape[0]):\n",
    "            target_q_val = reward_batch[idx]\n",
    "            if not done_batch[idx]:\n",
    "                target_q_val += self.discount_factor*q_max_next[idx]\n",
    "            q_target[idx, action_batch[idx]] = target_q_val\n",
    "        self.q_net.train_on_batch(state_batch, q_target)\n",
    "        self.epsilon = self.epsilon - self.epsilon_decay if self.epsilon > self.epsilon_final else self.epsilon_final\n",
    "        self.step_counter += 1\n",
    "\n",
    "    def train_model(self, env, num_episodes, graph):\n",
    "\n",
    "        scores, episodes, avg_scores, obj = [], [], [], []\n",
    "        goal = -110\n",
    "        f = 0\n",
    "        txt = open(\"saved_networks.txt\", \"w\")\n",
    "        steps_per_epsiode = []\n",
    "\n",
    "        for i in range(num_episodes):\n",
    "            done = False\n",
    "            score = 0.0\n",
    "            state = env.reset()\n",
    "            t = 0\n",
    "            while not done:\n",
    "                t = t + 1\n",
    "                action = self.policy(state)\n",
    "                new_state, reward, done, _ = env.step(action)\n",
    "                score += reward\n",
    "                self.store_tuple(state, action, reward, new_state, done)\n",
    "                state = new_state\n",
    "                self.train()\n",
    "            scores.append(score)\n",
    "            obj.append(goal)\n",
    "            steps_per_epsiode.append(t)\n",
    "            episodes.append(i)\n",
    "            avg_score = np.mean(scores[-100:])\n",
    "            avg_scores.append(avg_score)\n",
    "            print(\"Episode {0}, Score: {1} ({2}), AVG Score: {3}\".format(i, score, self.epsilon,\n",
    "                                                                             avg_score))\n",
    "            if avg_score >= -110 and score >= -108:\n",
    "                self.q_net.save((\"saved_networks/dqn_model{0}\".format(f)))\n",
    "                self.q_net.save_weights((\"saved_networks/dqn_model{0}/net_weights{0}.h5\".format(f)))\n",
    "                txt.write(\"Save {0} - Episode {1}/{2}, Score: {3} ({4}), AVG Score: {5}\\n\".format(f, i, num_episodes,score, self.epsilon,avg_score))\n",
    "                f += 1\n",
    "                print(\"Environment Solved in {} episodes\".format(i+1))\n",
    "                break\n",
    "\n",
    "        #txt.close()\n",
    "        if graph:\n",
    "            df = pd.DataFrame({'x': episodes, 'Score': scores, 'Average Score': avg_scores, 'Solved Requirement': obj})\n",
    "\n",
    "            #plt.plot('x', 'Score', data=df, marker='', color='blue', linewidth=2, label='Score')\n",
    "            plt.plot('x', 'Average Score', data=df, marker='', color='orange', linewidth=2, linestyle='dashed',\n",
    "                     label='AverageScore')\n",
    "            plt.plot('x', 'Solved Requirement', data=df, marker='', color='red', linewidth=2, linestyle='dashed',\n",
    "                     label='Solved Requirement')\n",
    "            plt.legend()\n",
    "            plt.savefig('MC_{}.png'.format(4))\n",
    "        return steps_per_epsiode\n",
    "\n",
    "\n",
    "    def test(self, env, num_episodes, file_type, file, graph):\n",
    "        if file_type == 'tf':\n",
    "            self.q_net = tf.keras.models.load_model(file)\n",
    "        elif file_type == 'h5':\n",
    "            self.train_model(env, 5, False)\n",
    "            self.q_net.load_weights(file)\n",
    "        self.epsilon = 0.0\n",
    "        scores, episodes, avg_scores, obj = [], [], [], []\n",
    "        goal = -110\n",
    "        score = 0.0\n",
    "        for i in range(num_episodes):\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            episode_score = 0.0\n",
    "            while not done:\n",
    "                env.render()\n",
    "                action = self.policy(state)\n",
    "                new_state, reward, done, _ = env.step(action)\n",
    "                episode_score += reward\n",
    "                state = new_state\n",
    "            score += episode_score\n",
    "            scores.append(episode_score)\n",
    "            obj.append(goal)\n",
    "            episodes.append(i)\n",
    "            avg_score = np.mean(scores[-100:])\n",
    "            avg_scores.append(avg_score)\n",
    "\n",
    "        if graph:\n",
    "            df = pd.DataFrame({'x': episodes, 'Score': scores, 'Average Score': avg_scores, 'Solved Requirement': obj})\n",
    "\n",
    "            #plt.plot('x', 'Score', data=df, marker='', color='blue', linewidth=2, label='Score')\n",
    "            plt.plot('x', 'Average Score', data=df, linewidth=2,\n",
    "                     label='AverageScore')\n",
    "            plt.plot('x', 'Solved Requirement', data=df, marker='', color='red', linewidth=2, linestyle='dashed',\n",
    "                     label='Solved Requirement')\n",
    "            plt.legend()\n",
    "            plt.savefig('MountainCar_Test.png')\n",
    "\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4-8BoB5iiyRf",
    "outputId": "d8fd13e1-584e-4afb-af71-baa4e928090b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Score: -200.0 (1.0), AVG Score: -200.0\n",
      "Episode 1, Score: -200.0 (0.9855000000000016), AVG Score: -200.0\n",
      "Episode 2, Score: -200.0 (0.9655000000000038), AVG Score: -200.0\n",
      "Episode 3, Score: -200.0 (0.945500000000006), AVG Score: -200.0\n",
      "Episode 4, Score: -200.0 (0.9255000000000082), AVG Score: -200.0\n",
      "Episode 5, Score: -200.0 (0.9055000000000104), AVG Score: -200.0\n",
      "Episode 6, Score: -200.0 (0.8855000000000126), AVG Score: -200.0\n",
      "Episode 7, Score: -200.0 (0.8655000000000148), AVG Score: -200.0\n",
      "Episode 8, Score: -200.0 (0.845500000000017), AVG Score: -200.0\n",
      "Episode 9, Score: -200.0 (0.8255000000000192), AVG Score: -200.0\n",
      "Episode 10, Score: -200.0 (0.8055000000000214), AVG Score: -200.0\n",
      "Episode 11, Score: -200.0 (0.7855000000000236), AVG Score: -200.0\n",
      "Episode 12, Score: -200.0 (0.7655000000000258), AVG Score: -200.0\n",
      "Episode 13, Score: -200.0 (0.745500000000028), AVG Score: -200.0\n",
      "Episode 14, Score: -200.0 (0.7255000000000302), AVG Score: -200.0\n",
      "Episode 15, Score: -200.0 (0.7055000000000324), AVG Score: -200.0\n",
      "Episode 16, Score: -200.0 (0.6855000000000346), AVG Score: -200.0\n",
      "Episode 17, Score: -200.0 (0.6655000000000368), AVG Score: -200.0\n",
      "Episode 18, Score: -200.0 (0.645500000000039), AVG Score: -200.0\n",
      "Episode 19, Score: -200.0 (0.6255000000000412), AVG Score: -200.0\n",
      "Episode 20, Score: -200.0 (0.6055000000000434), AVG Score: -200.0\n",
      "Episode 21, Score: -200.0 (0.5855000000000457), AVG Score: -200.0\n",
      "Episode 22, Score: -200.0 (0.5655000000000479), AVG Score: -200.0\n",
      "Episode 23, Score: -200.0 (0.5455000000000501), AVG Score: -200.0\n",
      "Episode 24, Score: -200.0 (0.5255000000000523), AVG Score: -200.0\n",
      "Episode 25, Score: -200.0 (0.5055000000000545), AVG Score: -200.0\n",
      "Episode 26, Score: -200.0 (0.48550000000005666), AVG Score: -200.0\n",
      "Episode 27, Score: -200.0 (0.46550000000005887), AVG Score: -200.0\n",
      "Episode 28, Score: -200.0 (0.44550000000006107), AVG Score: -200.0\n",
      "Episode 29, Score: -200.0 (0.42550000000006327), AVG Score: -200.0\n",
      "Episode 30, Score: -200.0 (0.4055000000000655), AVG Score: -200.0\n",
      "Episode 31, Score: -200.0 (0.3855000000000677), AVG Score: -200.0\n",
      "Episode 32, Score: -200.0 (0.3655000000000699), AVG Score: -200.0\n",
      "Episode 33, Score: -200.0 (0.3455000000000721), AVG Score: -200.0\n",
      "Episode 34, Score: -200.0 (0.3255000000000743), AVG Score: -200.0\n",
      "Episode 35, Score: -200.0 (0.3055000000000765), AVG Score: -200.0\n",
      "Episode 36, Score: -200.0 (0.2855000000000787), AVG Score: -200.0\n",
      "Episode 37, Score: -200.0 (0.2655000000000809), AVG Score: -200.0\n",
      "Episode 38, Score: -200.0 (0.2455000000000831), AVG Score: -200.0\n",
      "Episode 39, Score: -200.0 (0.2255000000000853), AVG Score: -200.0\n",
      "Episode 40, Score: -200.0 (0.2055000000000875), AVG Score: -200.0\n",
      "Episode 41, Score: -200.0 (0.1855000000000897), AVG Score: -200.0\n",
      "Episode 42, Score: -200.0 (0.1655000000000919), AVG Score: -200.0\n",
      "Episode 43, Score: -200.0 (0.1455000000000941), AVG Score: -200.0\n",
      "Episode 44, Score: -200.0 (0.1255000000000963), AVG Score: -200.0\n",
      "Episode 45, Score: -200.0 (0.10550000000009581), AVG Score: -200.0\n",
      "Episode 46, Score: -200.0 (0.08550000000009524), AVG Score: -200.0\n",
      "Episode 47, Score: -200.0 (0.06550000000009466), AVG Score: -200.0\n",
      "Episode 48, Score: -200.0 (0.04550000000009409), AVG Score: -200.0\n",
      "Episode 49, Score: -200.0 (0.02550000000009372), AVG Score: -200.0\n",
      "Episode 50, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 51, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 52, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 53, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 54, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 55, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 56, Score: -181.0 (0.01), AVG Score: -199.66666666666666\n",
      "Episode 57, Score: -161.0 (0.01), AVG Score: -199.0\n",
      "Episode 58, Score: -200.0 (0.01), AVG Score: -199.01694915254237\n",
      "Episode 59, Score: -195.0 (0.01), AVG Score: -198.95\n",
      "Episode 60, Score: -162.0 (0.01), AVG Score: -198.34426229508196\n",
      "Episode 61, Score: -151.0 (0.01), AVG Score: -197.58064516129033\n",
      "Episode 62, Score: -180.0 (0.01), AVG Score: -197.3015873015873\n",
      "Episode 63, Score: -160.0 (0.01), AVG Score: -196.71875\n",
      "Episode 64, Score: -151.0 (0.01), AVG Score: -196.01538461538462\n",
      "Episode 65, Score: -128.0 (0.01), AVG Score: -194.9848484848485\n",
      "Episode 66, Score: -161.0 (0.01), AVG Score: -194.47761194029852\n",
      "Episode 67, Score: -200.0 (0.01), AVG Score: -194.55882352941177\n",
      "Episode 68, Score: -200.0 (0.01), AVG Score: -194.63768115942028\n",
      "Episode 69, Score: -200.0 (0.01), AVG Score: -194.71428571428572\n",
      "Episode 70, Score: -160.0 (0.01), AVG Score: -194.22535211267606\n",
      "Episode 71, Score: -158.0 (0.01), AVG Score: -193.72222222222223\n",
      "Episode 72, Score: -200.0 (0.01), AVG Score: -193.8082191780822\n",
      "Episode 73, Score: -129.0 (0.01), AVG Score: -192.93243243243242\n",
      "Episode 74, Score: -200.0 (0.01), AVG Score: -193.02666666666667\n",
      "Episode 75, Score: -200.0 (0.01), AVG Score: -193.1184210526316\n",
      "Episode 76, Score: -189.0 (0.01), AVG Score: -193.06493506493507\n",
      "Episode 77, Score: -193.0 (0.01), AVG Score: -193.06410256410257\n",
      "Episode 78, Score: -200.0 (0.01), AVG Score: -193.15189873417722\n",
      "Episode 79, Score: -200.0 (0.01), AVG Score: -193.2375\n",
      "Episode 80, Score: -122.0 (0.01), AVG Score: -192.35802469135803\n",
      "Episode 81, Score: -149.0 (0.01), AVG Score: -191.82926829268294\n",
      "Episode 82, Score: -153.0 (0.01), AVG Score: -191.36144578313252\n",
      "Episode 83, Score: -126.0 (0.01), AVG Score: -190.58333333333334\n",
      "Episode 84, Score: -200.0 (0.01), AVG Score: -190.69411764705882\n",
      "Episode 85, Score: -137.0 (0.01), AVG Score: -190.06976744186048\n",
      "Episode 86, Score: -200.0 (0.01), AVG Score: -190.183908045977\n",
      "Episode 87, Score: -188.0 (0.01), AVG Score: -190.1590909090909\n",
      "Episode 88, Score: -200.0 (0.01), AVG Score: -190.26966292134833\n",
      "Episode 89, Score: -147.0 (0.01), AVG Score: -189.7888888888889\n",
      "Episode 90, Score: -151.0 (0.01), AVG Score: -189.36263736263737\n",
      "Episode 91, Score: -180.0 (0.01), AVG Score: -189.2608695652174\n",
      "Episode 92, Score: -113.0 (0.01), AVG Score: -188.44086021505376\n",
      "Episode 93, Score: -152.0 (0.01), AVG Score: -188.0531914893617\n",
      "Episode 94, Score: -172.0 (0.01), AVG Score: -187.8842105263158\n",
      "Episode 95, Score: -200.0 (0.01), AVG Score: -188.01041666666666\n",
      "Episode 96, Score: -129.0 (0.01), AVG Score: -187.4020618556701\n",
      "Episode 97, Score: -181.0 (0.01), AVG Score: -187.33673469387756\n",
      "Episode 98, Score: -113.0 (0.01), AVG Score: -186.58585858585857\n",
      "Episode 99, Score: -136.0 (0.01), AVG Score: -186.08\n",
      "Episode 100, Score: -177.0 (0.01), AVG Score: -185.85\n",
      "Episode 101, Score: -200.0 (0.01), AVG Score: -185.85\n",
      "Episode 102, Score: -87.0 (0.01), AVG Score: -184.72\n",
      "Episode 103, Score: -200.0 (0.01), AVG Score: -184.72\n",
      "Episode 104, Score: -194.0 (0.01), AVG Score: -184.66\n",
      "Episode 105, Score: -152.0 (0.01), AVG Score: -184.18\n",
      "Episode 106, Score: -170.0 (0.01), AVG Score: -183.88\n",
      "Episode 107, Score: -155.0 (0.01), AVG Score: -183.43\n",
      "Episode 108, Score: -154.0 (0.01), AVG Score: -182.97\n",
      "Episode 109, Score: -163.0 (0.01), AVG Score: -182.6\n",
      "Episode 110, Score: -177.0 (0.01), AVG Score: -182.37\n",
      "Episode 111, Score: -124.0 (0.01), AVG Score: -181.61\n",
      "Episode 112, Score: -142.0 (0.01), AVG Score: -181.03\n",
      "Episode 113, Score: -127.0 (0.01), AVG Score: -180.3\n",
      "Episode 114, Score: -170.0 (0.01), AVG Score: -180.0\n",
      "Episode 115, Score: -126.0 (0.01), AVG Score: -179.26\n",
      "Episode 116, Score: -150.0 (0.01), AVG Score: -178.76\n",
      "Episode 117, Score: -128.0 (0.01), AVG Score: -178.04\n",
      "Episode 118, Score: -156.0 (0.01), AVG Score: -177.6\n",
      "Episode 119, Score: -159.0 (0.01), AVG Score: -177.19\n",
      "Episode 120, Score: -93.0 (0.01), AVG Score: -176.12\n",
      "Episode 121, Score: -153.0 (0.01), AVG Score: -175.65\n",
      "Episode 122, Score: -153.0 (0.01), AVG Score: -175.18\n",
      "Episode 123, Score: -180.0 (0.01), AVG Score: -174.98\n",
      "Episode 124, Score: -145.0 (0.01), AVG Score: -174.43\n",
      "Episode 125, Score: -200.0 (0.01), AVG Score: -174.43\n",
      "Episode 126, Score: -195.0 (0.01), AVG Score: -174.38\n",
      "Episode 127, Score: -183.0 (0.01), AVG Score: -174.21\n",
      "Episode 128, Score: -198.0 (0.01), AVG Score: -174.19\n",
      "Episode 129, Score: -148.0 (0.01), AVG Score: -173.67\n",
      "Episode 130, Score: -153.0 (0.01), AVG Score: -173.2\n",
      "Episode 131, Score: -200.0 (0.01), AVG Score: -173.2\n",
      "Episode 132, Score: -162.0 (0.01), AVG Score: -172.82\n",
      "Episode 133, Score: -164.0 (0.01), AVG Score: -172.46\n",
      "Episode 134, Score: -143.0 (0.01), AVG Score: -171.89\n",
      "Episode 135, Score: -149.0 (0.01), AVG Score: -171.38\n",
      "Episode 136, Score: -177.0 (0.01), AVG Score: -171.15\n",
      "Episode 137, Score: -155.0 (0.01), AVG Score: -170.7\n",
      "Episode 138, Score: -162.0 (0.01), AVG Score: -170.32\n",
      "Episode 139, Score: -96.0 (0.01), AVG Score: -169.28\n",
      "Episode 140, Score: -137.0 (0.01), AVG Score: -168.65\n",
      "Episode 141, Score: -122.0 (0.01), AVG Score: -167.87\n",
      "Episode 142, Score: -141.0 (0.01), AVG Score: -167.28\n",
      "Episode 143, Score: -114.0 (0.01), AVG Score: -166.42\n",
      "Episode 144, Score: -160.0 (0.01), AVG Score: -166.02\n",
      "Episode 145, Score: -142.0 (0.01), AVG Score: -165.44\n",
      "Episode 146, Score: -168.0 (0.01), AVG Score: -165.12\n",
      "Episode 147, Score: -116.0 (0.01), AVG Score: -164.28\n",
      "Episode 148, Score: -161.0 (0.01), AVG Score: -163.89\n",
      "Episode 149, Score: -197.0 (0.01), AVG Score: -163.86\n",
      "Episode 150, Score: -168.0 (0.01), AVG Score: -163.54\n",
      "Episode 151, Score: -182.0 (0.01), AVG Score: -163.36\n",
      "Episode 152, Score: -189.0 (0.01), AVG Score: -163.25\n",
      "Episode 153, Score: -194.0 (0.01), AVG Score: -163.19\n",
      "Episode 154, Score: -186.0 (0.01), AVG Score: -163.05\n",
      "Episode 155, Score: -134.0 (0.01), AVG Score: -162.39\n",
      "Episode 156, Score: -200.0 (0.01), AVG Score: -162.58\n",
      "Episode 157, Score: -163.0 (0.01), AVG Score: -162.6\n",
      "Episode 158, Score: -200.0 (0.01), AVG Score: -162.6\n",
      "Episode 159, Score: -146.0 (0.01), AVG Score: -162.11\n",
      "Episode 160, Score: -194.0 (0.01), AVG Score: -162.43\n",
      "Episode 161, Score: -200.0 (0.01), AVG Score: -162.92\n",
      "Episode 162, Score: -187.0 (0.01), AVG Score: -162.99\n",
      "Episode 163, Score: -112.0 (0.01), AVG Score: -162.51\n",
      "Episode 164, Score: -138.0 (0.01), AVG Score: -162.38\n",
      "Episode 165, Score: -152.0 (0.01), AVG Score: -162.62\n",
      "Episode 166, Score: -167.0 (0.01), AVG Score: -162.68\n",
      "Episode 167, Score: -180.0 (0.01), AVG Score: -162.48\n",
      "Episode 168, Score: -200.0 (0.01), AVG Score: -162.48\n",
      "Episode 169, Score: -173.0 (0.01), AVG Score: -162.21\n",
      "Episode 170, Score: -123.0 (0.01), AVG Score: -161.84\n",
      "Episode 171, Score: -150.0 (0.01), AVG Score: -161.76\n",
      "Episode 172, Score: -146.0 (0.01), AVG Score: -161.22\n",
      "Episode 173, Score: -146.0 (0.01), AVG Score: -161.39\n",
      "Episode 174, Score: -142.0 (0.01), AVG Score: -160.81\n",
      "Episode 175, Score: -173.0 (0.01), AVG Score: -160.54\n",
      "Episode 176, Score: -157.0 (0.01), AVG Score: -160.22\n",
      "Episode 177, Score: -137.0 (0.01), AVG Score: -159.66\n",
      "Episode 178, Score: -157.0 (0.01), AVG Score: -159.23\n",
      "Episode 179, Score: -200.0 (0.01), AVG Score: -159.23\n",
      "Episode 180, Score: -136.0 (0.01), AVG Score: -159.37\n",
      "Episode 181, Score: -109.0 (0.01), AVG Score: -158.97\n",
      "Episode 182, Score: -110.0 (0.01), AVG Score: -158.54\n",
      "Episode 183, Score: -155.0 (0.01), AVG Score: -158.83\n",
      "Episode 184, Score: -177.0 (0.01), AVG Score: -158.6\n",
      "Episode 185, Score: -158.0 (0.01), AVG Score: -158.81\n",
      "Episode 186, Score: -155.0 (0.01), AVG Score: -158.36\n",
      "Episode 187, Score: -147.0 (0.01), AVG Score: -157.95\n",
      "Episode 188, Score: -143.0 (0.01), AVG Score: -157.38\n",
      "Episode 189, Score: -185.0 (0.01), AVG Score: -157.76\n",
      "Episode 190, Score: -107.0 (0.01), AVG Score: -157.32\n",
      "Episode 191, Score: -135.0 (0.01), AVG Score: -156.87\n",
      "Episode 192, Score: -116.0 (0.01), AVG Score: -156.9\n",
      "Episode 193, Score: -136.0 (0.01), AVG Score: -156.74\n",
      "Episode 194, Score: -144.0 (0.01), AVG Score: -156.46\n",
      "Episode 195, Score: -115.0 (0.01), AVG Score: -155.61\n",
      "Episode 196, Score: -118.0 (0.01), AVG Score: -155.5\n",
      "Episode 197, Score: -139.0 (0.01), AVG Score: -155.08\n",
      "Episode 198, Score: -109.0 (0.01), AVG Score: -155.04\n",
      "Episode 199, Score: -119.0 (0.01), AVG Score: -154.87\n",
      "Episode 200, Score: -100.0 (0.01), AVG Score: -154.1\n",
      "Episode 201, Score: -132.0 (0.01), AVG Score: -153.42\n",
      "Episode 202, Score: -89.0 (0.01), AVG Score: -153.44\n",
      "Episode 203, Score: -143.0 (0.01), AVG Score: -152.87\n",
      "Episode 204, Score: -117.0 (0.01), AVG Score: -152.1\n",
      "Episode 205, Score: -104.0 (0.01), AVG Score: -151.62\n",
      "Episode 206, Score: -126.0 (0.01), AVG Score: -151.18\n",
      "Episode 207, Score: -84.0 (0.01), AVG Score: -150.47\n",
      "Episode 208, Score: -97.0 (0.01), AVG Score: -149.9\n",
      "Episode 209, Score: -124.0 (0.01), AVG Score: -149.51\n",
      "Episode 210, Score: -102.0 (0.01), AVG Score: -148.76\n",
      "Episode 211, Score: -124.0 (0.01), AVG Score: -148.76\n",
      "Episode 212, Score: -157.0 (0.01), AVG Score: -148.91\n",
      "Episode 213, Score: -182.0 (0.01), AVG Score: -149.46\n",
      "Episode 214, Score: -141.0 (0.01), AVG Score: -149.17\n",
      "Episode 215, Score: -112.0 (0.01), AVG Score: -149.03\n",
      "Episode 216, Score: -161.0 (0.01), AVG Score: -149.14\n",
      "Episode 217, Score: -138.0 (0.01), AVG Score: -149.24\n",
      "Episode 218, Score: -137.0 (0.01), AVG Score: -149.05\n",
      "Episode 219, Score: -163.0 (0.01), AVG Score: -149.09\n",
      "Episode 220, Score: -153.0 (0.01), AVG Score: -149.69\n",
      "Episode 221, Score: -200.0 (0.01), AVG Score: -150.16\n",
      "Episode 222, Score: -120.0 (0.01), AVG Score: -149.83\n",
      "Episode 223, Score: -163.0 (0.01), AVG Score: -149.66\n",
      "Episode 224, Score: -121.0 (0.01), AVG Score: -149.42\n",
      "Episode 225, Score: -160.0 (0.01), AVG Score: -149.02\n",
      "Episode 226, Score: -151.0 (0.01), AVG Score: -148.58\n",
      "Episode 227, Score: -107.0 (0.01), AVG Score: -147.82\n",
      "Episode 228, Score: -149.0 (0.01), AVG Score: -147.33\n",
      "Episode 229, Score: -146.0 (0.01), AVG Score: -147.31\n",
      "Episode 230, Score: -106.0 (0.01), AVG Score: -146.84\n",
      "Episode 231, Score: -174.0 (0.01), AVG Score: -146.58\n",
      "Episode 232, Score: -111.0 (0.01), AVG Score: -146.07\n",
      "Episode 233, Score: -146.0 (0.01), AVG Score: -145.89\n",
      "Episode 234, Score: -91.0 (0.01), AVG Score: -145.37\n",
      "Episode 235, Score: -171.0 (0.01), AVG Score: -145.59\n",
      "Episode 236, Score: -156.0 (0.01), AVG Score: -145.38\n",
      "Episode 237, Score: -121.0 (0.01), AVG Score: -145.04\n",
      "Episode 238, Score: -96.0 (0.01), AVG Score: -144.38\n",
      "Episode 239, Score: -200.0 (0.01), AVG Score: -145.42\n",
      "Episode 240, Score: -193.0 (0.01), AVG Score: -145.98\n",
      "Episode 241, Score: -90.0 (0.01), AVG Score: -145.66\n",
      "Episode 242, Score: -136.0 (0.01), AVG Score: -145.61\n",
      "Episode 243, Score: -121.0 (0.01), AVG Score: -145.68\n",
      "Episode 244, Score: -103.0 (0.01), AVG Score: -145.11\n",
      "Episode 245, Score: -113.0 (0.01), AVG Score: -144.82\n",
      "Episode 246, Score: -121.0 (0.01), AVG Score: -144.35\n",
      "Episode 247, Score: -120.0 (0.01), AVG Score: -144.39\n",
      "Episode 248, Score: -114.0 (0.01), AVG Score: -143.92\n",
      "Episode 249, Score: -156.0 (0.01), AVG Score: -143.51\n",
      "Episode 250, Score: -108.0 (0.01), AVG Score: -142.91\n",
      "Episode 251, Score: -200.0 (0.01), AVG Score: -143.09\n",
      "Episode 252, Score: -84.0 (0.01), AVG Score: -142.04\n",
      "Episode 253, Score: -127.0 (0.01), AVG Score: -141.37\n",
      "Episode 254, Score: -168.0 (0.01), AVG Score: -141.19\n",
      "Episode 255, Score: -166.0 (0.01), AVG Score: -141.51\n",
      "Episode 256, Score: -88.0 (0.01), AVG Score: -140.39\n",
      "Episode 257, Score: -90.0 (0.01), AVG Score: -139.66\n",
      "Episode 258, Score: -156.0 (0.01), AVG Score: -139.22\n",
      "Episode 259, Score: -182.0 (0.01), AVG Score: -139.58\n",
      "Episode 260, Score: -133.0 (0.01), AVG Score: -138.97\n",
      "Episode 261, Score: -141.0 (0.01), AVG Score: -138.38\n",
      "Episode 262, Score: -131.0 (0.01), AVG Score: -137.82\n",
      "Episode 263, Score: -88.0 (0.01), AVG Score: -137.58\n",
      "Episode 264, Score: -136.0 (0.01), AVG Score: -137.56\n",
      "Episode 265, Score: -122.0 (0.01), AVG Score: -137.26\n",
      "Episode 266, Score: -145.0 (0.01), AVG Score: -137.04\n",
      "Episode 267, Score: -111.0 (0.01), AVG Score: -136.35\n",
      "Episode 268, Score: -120.0 (0.01), AVG Score: -135.55\n",
      "Episode 269, Score: -142.0 (0.01), AVG Score: -135.24\n",
      "Episode 270, Score: -116.0 (0.01), AVG Score: -135.17\n",
      "Episode 271, Score: -149.0 (0.01), AVG Score: -135.16\n",
      "Episode 272, Score: -134.0 (0.01), AVG Score: -135.04\n",
      "Episode 273, Score: -141.0 (0.01), AVG Score: -134.99\n",
      "Episode 274, Score: -171.0 (0.01), AVG Score: -135.28\n",
      "Episode 275, Score: -113.0 (0.01), AVG Score: -134.68\n",
      "Episode 276, Score: -177.0 (0.01), AVG Score: -134.88\n",
      "Episode 277, Score: -117.0 (0.01), AVG Score: -134.68\n",
      "Episode 278, Score: -113.0 (0.01), AVG Score: -134.24\n",
      "Episode 279, Score: -144.0 (0.01), AVG Score: -133.68\n",
      "Episode 280, Score: -103.0 (0.01), AVG Score: -133.35\n",
      "Episode 281, Score: -144.0 (0.01), AVG Score: -133.7\n",
      "Episode 282, Score: -163.0 (0.01), AVG Score: -134.23\n",
      "Episode 283, Score: -112.0 (0.01), AVG Score: -133.8\n",
      "Episode 284, Score: -154.0 (0.01), AVG Score: -133.57\n",
      "Episode 285, Score: -114.0 (0.01), AVG Score: -133.13\n",
      "Episode 286, Score: -106.0 (0.01), AVG Score: -132.64\n",
      "Episode 287, Score: -156.0 (0.01), AVG Score: -132.73\n",
      "Episode 288, Score: -155.0 (0.01), AVG Score: -132.85\n",
      "Episode 289, Score: -145.0 (0.01), AVG Score: -132.45\n",
      "Episode 290, Score: -110.0 (0.01), AVG Score: -132.48\n",
      "Episode 291, Score: -116.0 (0.01), AVG Score: -132.29\n",
      "Episode 292, Score: -155.0 (0.01), AVG Score: -132.68\n",
      "Episode 293, Score: -128.0 (0.01), AVG Score: -132.6\n",
      "Episode 294, Score: -119.0 (0.01), AVG Score: -132.35\n",
      "Episode 295, Score: -146.0 (0.01), AVG Score: -132.66\n",
      "Episode 296, Score: -148.0 (0.01), AVG Score: -132.96\n",
      "Episode 297, Score: -116.0 (0.01), AVG Score: -132.73\n",
      "Episode 298, Score: -152.0 (0.01), AVG Score: -133.16\n",
      "Episode 299, Score: -108.0 (0.01), AVG Score: -133.05\n",
      "Episode 300, Score: -110.0 (0.01), AVG Score: -133.15\n",
      "Episode 301, Score: -106.0 (0.01), AVG Score: -132.89\n",
      "Episode 302, Score: -107.0 (0.01), AVG Score: -133.07\n",
      "Episode 303, Score: -100.0 (0.01), AVG Score: -132.64\n",
      "Episode 304, Score: -112.0 (0.01), AVG Score: -132.59\n",
      "Episode 305, Score: -104.0 (0.01), AVG Score: -132.59\n",
      "Episode 306, Score: -106.0 (0.01), AVG Score: -132.39\n",
      "Episode 307, Score: -148.0 (0.01), AVG Score: -133.03\n",
      "Episode 308, Score: -108.0 (0.01), AVG Score: -133.14\n",
      "Episode 309, Score: -170.0 (0.01), AVG Score: -133.6\n",
      "Episode 310, Score: -84.0 (0.01), AVG Score: -133.42\n",
      "Episode 311, Score: -160.0 (0.01), AVG Score: -133.78\n",
      "Episode 312, Score: -110.0 (0.01), AVG Score: -133.31\n",
      "Episode 313, Score: -84.0 (0.01), AVG Score: -132.33\n",
      "Episode 314, Score: -133.0 (0.01), AVG Score: -132.25\n",
      "Episode 315, Score: -150.0 (0.01), AVG Score: -132.63\n",
      "Episode 316, Score: -89.0 (0.01), AVG Score: -131.91\n",
      "Episode 317, Score: -151.0 (0.01), AVG Score: -132.04\n",
      "Episode 318, Score: -140.0 (0.01), AVG Score: -132.07\n",
      "Episode 319, Score: -190.0 (0.01), AVG Score: -132.34\n",
      "Episode 320, Score: -111.0 (0.01), AVG Score: -131.92\n",
      "Episode 321, Score: -109.0 (0.01), AVG Score: -131.01\n",
      "Episode 322, Score: -114.0 (0.01), AVG Score: -130.95\n",
      "Episode 323, Score: -86.0 (0.01), AVG Score: -130.18\n",
      "Episode 324, Score: -112.0 (0.01), AVG Score: -130.09\n",
      "Episode 325, Score: -117.0 (0.01), AVG Score: -129.66\n",
      "Episode 326, Score: -152.0 (0.01), AVG Score: -129.67\n",
      "Episode 327, Score: -153.0 (0.01), AVG Score: -130.13\n",
      "Episode 328, Score: -130.0 (0.01), AVG Score: -129.94\n",
      "Episode 329, Score: -114.0 (0.01), AVG Score: -129.62\n",
      "Episode 330, Score: -110.0 (0.01), AVG Score: -129.66\n",
      "Episode 331, Score: -122.0 (0.01), AVG Score: -129.14\n",
      "Episode 332, Score: -93.0 (0.01), AVG Score: -128.96\n",
      "Episode 333, Score: -142.0 (0.01), AVG Score: -128.92\n",
      "Episode 334, Score: -110.0 (0.01), AVG Score: -129.11\n",
      "Episode 335, Score: -90.0 (0.01), AVG Score: -128.3\n",
      "Episode 336, Score: -116.0 (0.01), AVG Score: -127.9\n",
      "Episode 337, Score: -120.0 (0.01), AVG Score: -127.89\n",
      "Episode 338, Score: -107.0 (0.01), AVG Score: -128.0\n",
      "Episode 339, Score: -146.0 (0.01), AVG Score: -127.46\n",
      "Episode 340, Score: -117.0 (0.01), AVG Score: -126.7\n",
      "Episode 341, Score: -154.0 (0.01), AVG Score: -127.34\n",
      "Episode 342, Score: -86.0 (0.01), AVG Score: -126.84\n",
      "Episode 343, Score: -114.0 (0.01), AVG Score: -126.77\n",
      "Episode 344, Score: -147.0 (0.01), AVG Score: -127.21\n",
      "Episode 345, Score: -113.0 (0.01), AVG Score: -127.21\n",
      "Episode 346, Score: -131.0 (0.01), AVG Score: -127.31\n",
      "Episode 347, Score: -136.0 (0.01), AVG Score: -127.47\n",
      "Episode 348, Score: -181.0 (0.01), AVG Score: -128.14\n",
      "Episode 349, Score: -126.0 (0.01), AVG Score: -127.84\n",
      "Episode 350, Score: -124.0 (0.01), AVG Score: -128.0\n",
      "Episode 351, Score: -156.0 (0.01), AVG Score: -127.56\n",
      "Episode 352, Score: -86.0 (0.01), AVG Score: -127.58\n",
      "Episode 353, Score: -140.0 (0.01), AVG Score: -127.71\n",
      "Episode 354, Score: -196.0 (0.01), AVG Score: -127.99\n",
      "Episode 355, Score: -170.0 (0.01), AVG Score: -128.03\n",
      "Episode 356, Score: -95.0 (0.01), AVG Score: -128.1\n",
      "Episode 357, Score: -130.0 (0.01), AVG Score: -128.5\n",
      "Episode 358, Score: -131.0 (0.01), AVG Score: -128.25\n",
      "Episode 359, Score: -142.0 (0.01), AVG Score: -127.85\n",
      "Episode 360, Score: -123.0 (0.01), AVG Score: -127.75\n",
      "Episode 361, Score: -142.0 (0.01), AVG Score: -127.76\n",
      "Episode 362, Score: -93.0 (0.01), AVG Score: -127.38\n",
      "Episode 363, Score: -166.0 (0.01), AVG Score: -128.16\n",
      "Episode 364, Score: -117.0 (0.01), AVG Score: -127.97\n",
      "Episode 365, Score: -111.0 (0.01), AVG Score: -127.86\n",
      "Episode 366, Score: -125.0 (0.01), AVG Score: -127.66\n",
      "Episode 367, Score: -124.0 (0.01), AVG Score: -127.79\n",
      "Episode 368, Score: -160.0 (0.01), AVG Score: -128.19\n",
      "Episode 369, Score: -110.0 (0.01), AVG Score: -127.87\n",
      "Episode 370, Score: -116.0 (0.01), AVG Score: -127.87\n",
      "Episode 371, Score: -118.0 (0.01), AVG Score: -127.56\n",
      "Episode 372, Score: -92.0 (0.01), AVG Score: -127.14\n",
      "Episode 373, Score: -101.0 (0.01), AVG Score: -126.74\n",
      "Episode 374, Score: -164.0 (0.01), AVG Score: -126.67\n",
      "Episode 375, Score: -92.0 (0.01), AVG Score: -126.46\n",
      "Episode 376, Score: -140.0 (0.01), AVG Score: -126.09\n",
      "Episode 377, Score: -159.0 (0.01), AVG Score: -126.51\n",
      "Episode 378, Score: -122.0 (0.01), AVG Score: -126.6\n",
      "Episode 379, Score: -97.0 (0.01), AVG Score: -126.13\n",
      "Episode 380, Score: -160.0 (0.01), AVG Score: -126.7\n",
      "Episode 381, Score: -150.0 (0.01), AVG Score: -126.76\n",
      "Episode 382, Score: -125.0 (0.01), AVG Score: -126.38\n",
      "Episode 383, Score: -115.0 (0.01), AVG Score: -126.41\n",
      "Episode 384, Score: -117.0 (0.01), AVG Score: -126.04\n",
      "Episode 385, Score: -189.0 (0.01), AVG Score: -126.79\n",
      "Episode 386, Score: -178.0 (0.01), AVG Score: -127.51\n",
      "Episode 387, Score: -122.0 (0.01), AVG Score: -127.17\n",
      "Episode 388, Score: -113.0 (0.01), AVG Score: -126.75\n",
      "Episode 389, Score: -123.0 (0.01), AVG Score: -126.53\n",
      "Episode 390, Score: -113.0 (0.01), AVG Score: -126.56\n",
      "Episode 391, Score: -157.0 (0.01), AVG Score: -126.97\n",
      "Episode 392, Score: -106.0 (0.01), AVG Score: -126.48\n",
      "Episode 393, Score: -133.0 (0.01), AVG Score: -126.53\n",
      "Episode 394, Score: -103.0 (0.01), AVG Score: -126.37\n",
      "Episode 395, Score: -86.0 (0.01), AVG Score: -125.77\n",
      "Episode 396, Score: -104.0 (0.01), AVG Score: -125.33\n",
      "Episode 397, Score: -150.0 (0.01), AVG Score: -125.67\n",
      "Episode 398, Score: -162.0 (0.01), AVG Score: -125.77\n",
      "Episode 399, Score: -118.0 (0.01), AVG Score: -125.87\n",
      "Episode 400, Score: -155.0 (0.01), AVG Score: -126.32\n",
      "Episode 401, Score: -161.0 (0.01), AVG Score: -126.87\n",
      "Episode 402, Score: -112.0 (0.01), AVG Score: -126.92\n",
      "Episode 403, Score: -142.0 (0.01), AVG Score: -127.34\n",
      "Episode 404, Score: -125.0 (0.01), AVG Score: -127.47\n",
      "Episode 405, Score: -92.0 (0.01), AVG Score: -127.35\n",
      "Episode 406, Score: -139.0 (0.01), AVG Score: -127.68\n",
      "Episode 407, Score: -117.0 (0.01), AVG Score: -127.37\n",
      "Episode 408, Score: -115.0 (0.01), AVG Score: -127.44\n",
      "Episode 409, Score: -177.0 (0.01), AVG Score: -127.51\n",
      "Episode 410, Score: -109.0 (0.01), AVG Score: -127.76\n",
      "Episode 411, Score: -118.0 (0.01), AVG Score: -127.34\n",
      "Episode 412, Score: -119.0 (0.01), AVG Score: -127.43\n",
      "Episode 413, Score: -93.0 (0.01), AVG Score: -127.52\n",
      "Episode 414, Score: -117.0 (0.01), AVG Score: -127.36\n",
      "Episode 415, Score: -114.0 (0.01), AVG Score: -127.0\n",
      "Episode 416, Score: -115.0 (0.01), AVG Score: -127.26\n",
      "Episode 417, Score: -178.0 (0.01), AVG Score: -127.53\n",
      "Episode 418, Score: -108.0 (0.01), AVG Score: -127.21\n",
      "Episode 419, Score: -131.0 (0.01), AVG Score: -126.62\n",
      "Episode 420, Score: -160.0 (0.01), AVG Score: -127.11\n",
      "Episode 421, Score: -116.0 (0.01), AVG Score: -127.18\n",
      "Episode 422, Score: -113.0 (0.01), AVG Score: -127.17\n",
      "Episode 423, Score: -86.0 (0.01), AVG Score: -127.17\n",
      "Episode 424, Score: -112.0 (0.01), AVG Score: -127.17\n",
      "Episode 425, Score: -92.0 (0.01), AVG Score: -126.92\n",
      "Episode 426, Score: -111.0 (0.01), AVG Score: -126.51\n",
      "Episode 427, Score: -113.0 (0.01), AVG Score: -126.11\n",
      "Episode 428, Score: -89.0 (0.01), AVG Score: -125.7\n",
      "Episode 429, Score: -110.0 (0.01), AVG Score: -125.66\n",
      "Episode 430, Score: -109.0 (0.01), AVG Score: -125.65\n",
      "Episode 431, Score: -151.0 (0.01), AVG Score: -125.94\n",
      "Episode 432, Score: -191.0 (0.01), AVG Score: -126.92\n",
      "Episode 433, Score: -100.0 (0.01), AVG Score: -126.5\n",
      "Episode 434, Score: -126.0 (0.01), AVG Score: -126.66\n",
      "Episode 435, Score: -107.0 (0.01), AVG Score: -126.83\n",
      "Episode 436, Score: -140.0 (0.01), AVG Score: -127.07\n",
      "Episode 437, Score: -133.0 (0.01), AVG Score: -127.2\n",
      "Episode 438, Score: -116.0 (0.01), AVG Score: -127.29\n",
      "Episode 439, Score: -113.0 (0.01), AVG Score: -126.96\n",
      "Episode 440, Score: -113.0 (0.01), AVG Score: -126.92\n",
      "Episode 441, Score: -116.0 (0.01), AVG Score: -126.54\n",
      "Episode 442, Score: -118.0 (0.01), AVG Score: -126.86\n",
      "Episode 443, Score: -167.0 (0.01), AVG Score: -127.39\n",
      "Episode 444, Score: -105.0 (0.01), AVG Score: -126.97\n",
      "Episode 445, Score: -94.0 (0.01), AVG Score: -126.78\n",
      "Episode 446, Score: -200.0 (0.01), AVG Score: -127.47\n",
      "Episode 447, Score: -109.0 (0.01), AVG Score: -127.2\n",
      "Episode 448, Score: -173.0 (0.01), AVG Score: -127.12\n",
      "Episode 449, Score: -158.0 (0.01), AVG Score: -127.44\n",
      "Episode 450, Score: -112.0 (0.01), AVG Score: -127.32\n",
      "Episode 451, Score: -106.0 (0.01), AVG Score: -126.82\n",
      "Episode 452, Score: -111.0 (0.01), AVG Score: -127.07\n",
      "Episode 453, Score: -94.0 (0.01), AVG Score: -126.61\n",
      "Episode 454, Score: -152.0 (0.01), AVG Score: -126.17\n",
      "Episode 455, Score: -111.0 (0.01), AVG Score: -125.58\n",
      "Episode 456, Score: -103.0 (0.01), AVG Score: -125.66\n",
      "Episode 457, Score: -128.0 (0.01), AVG Score: -125.64\n",
      "Episode 458, Score: -95.0 (0.01), AVG Score: -125.28\n",
      "Episode 459, Score: -132.0 (0.01), AVG Score: -125.18\n",
      "Episode 460, Score: -107.0 (0.01), AVG Score: -125.02\n",
      "Episode 461, Score: -112.0 (0.01), AVG Score: -124.72\n",
      "Episode 462, Score: -96.0 (0.01), AVG Score: -124.75\n",
      "Episode 463, Score: -99.0 (0.01), AVG Score: -124.08\n",
      "Episode 464, Score: -128.0 (0.01), AVG Score: -124.19\n",
      "Episode 465, Score: -88.0 (0.01), AVG Score: -123.96\n",
      "Episode 466, Score: -88.0 (0.01), AVG Score: -123.59\n",
      "Episode 467, Score: -105.0 (0.01), AVG Score: -123.4\n",
      "Episode 468, Score: -135.0 (0.01), AVG Score: -123.15\n",
      "Episode 469, Score: -111.0 (0.01), AVG Score: -123.16\n",
      "Episode 470, Score: -91.0 (0.01), AVG Score: -122.91\n",
      "Episode 471, Score: -112.0 (0.01), AVG Score: -122.85\n",
      "Episode 472, Score: -96.0 (0.01), AVG Score: -122.89\n",
      "Episode 473, Score: -113.0 (0.01), AVG Score: -123.01\n",
      "Episode 474, Score: -151.0 (0.01), AVG Score: -122.88\n",
      "Episode 475, Score: -111.0 (0.01), AVG Score: -123.07\n",
      "Episode 476, Score: -152.0 (0.01), AVG Score: -123.19\n",
      "Episode 477, Score: -132.0 (0.01), AVG Score: -122.92\n",
      "Episode 478, Score: -191.0 (0.01), AVG Score: -123.61\n",
      "Episode 479, Score: -116.0 (0.01), AVG Score: -123.8\n",
      "Episode 480, Score: -103.0 (0.01), AVG Score: -123.23\n",
      "Episode 481, Score: -88.0 (0.01), AVG Score: -122.61\n",
      "Episode 482, Score: -105.0 (0.01), AVG Score: -122.41\n",
      "Episode 483, Score: -119.0 (0.01), AVG Score: -122.45\n",
      "Episode 484, Score: -91.0 (0.01), AVG Score: -122.19\n",
      "Episode 485, Score: -88.0 (0.01), AVG Score: -121.18\n",
      "Episode 486, Score: -112.0 (0.01), AVG Score: -120.52\n",
      "Episode 487, Score: -111.0 (0.01), AVG Score: -120.41\n",
      "Episode 488, Score: -101.0 (0.01), AVG Score: -120.29\n",
      "Episode 489, Score: -140.0 (0.01), AVG Score: -120.46\n",
      "Episode 490, Score: -91.0 (0.01), AVG Score: -120.24\n",
      "Episode 491, Score: -113.0 (0.01), AVG Score: -119.8\n",
      "Episode 492, Score: -90.0 (0.01), AVG Score: -119.64\n",
      "Episode 493, Score: -84.0 (0.01), AVG Score: -119.15\n",
      "Episode 494, Score: -97.0 (0.01), AVG Score: -119.09\n",
      "Episode 495, Score: -85.0 (0.01), AVG Score: -119.08\n",
      "Episode 496, Score: -97.0 (0.01), AVG Score: -119.01\n",
      "Episode 497, Score: -110.0 (0.01), AVG Score: -118.61\n",
      "Episode 498, Score: -105.0 (0.01), AVG Score: -118.04\n",
      "Episode 499, Score: -102.0 (0.01), AVG Score: -117.88\n",
      "Episode 500, Score: -94.0 (0.01), AVG Score: -117.27\n",
      "Episode 501, Score: -112.0 (0.01), AVG Score: -116.78\n",
      "Episode 502, Score: -172.0 (0.01), AVG Score: -117.38\n",
      "Episode 503, Score: -112.0 (0.01), AVG Score: -117.08\n",
      "Episode 504, Score: -111.0 (0.01), AVG Score: -116.94\n",
      "Episode 505, Score: -96.0 (0.01), AVG Score: -116.98\n",
      "Episode 506, Score: -107.0 (0.01), AVG Score: -116.66\n",
      "Episode 507, Score: -96.0 (0.01), AVG Score: -116.45\n",
      "Episode 508, Score: -128.0 (0.01), AVG Score: -116.58\n",
      "Episode 509, Score: -94.0 (0.01), AVG Score: -115.75\n",
      "Episode 510, Score: -85.0 (0.01), AVG Score: -115.51\n",
      "Episode 511, Score: -92.0 (0.01), AVG Score: -115.25\n",
      "Episode 512, Score: -105.0 (0.01), AVG Score: -115.11\n",
      "Episode 513, Score: -92.0 (0.01), AVG Score: -115.1\n",
      "Episode 514, Score: -91.0 (0.01), AVG Score: -114.84\n",
      "Episode 515, Score: -113.0 (0.01), AVG Score: -114.83\n",
      "Episode 516, Score: -96.0 (0.01), AVG Score: -114.64\n",
      "Episode 517, Score: -116.0 (0.01), AVG Score: -114.02\n",
      "Episode 518, Score: -91.0 (0.01), AVG Score: -113.85\n",
      "Episode 519, Score: -105.0 (0.01), AVG Score: -113.59\n",
      "Episode 520, Score: -85.0 (0.01), AVG Score: -112.84\n",
      "Episode 521, Score: -116.0 (0.01), AVG Score: -112.84\n",
      "Episode 522, Score: -86.0 (0.01), AVG Score: -112.57\n",
      "Episode 523, Score: -108.0 (0.01), AVG Score: -112.79\n",
      "Episode 524, Score: -95.0 (0.01), AVG Score: -112.62\n",
      "Episode 525, Score: -106.0 (0.01), AVG Score: -112.76\n",
      "Episode 526, Score: -115.0 (0.01), AVG Score: -112.8\n",
      "Episode 527, Score: -109.0 (0.01), AVG Score: -112.76\n",
      "Episode 528, Score: -110.0 (0.01), AVG Score: -112.97\n",
      "Episode 529, Score: -155.0 (0.01), AVG Score: -113.42\n",
      "Episode 530, Score: -113.0 (0.01), AVG Score: -113.46\n",
      "Episode 531, Score: -115.0 (0.01), AVG Score: -113.1\n",
      "Episode 532, Score: -103.0 (0.01), AVG Score: -112.22\n",
      "Episode 533, Score: -112.0 (0.01), AVG Score: -112.34\n",
      "Episode 534, Score: -103.0 (0.01), AVG Score: -112.11\n",
      "Episode 535, Score: -110.0 (0.01), AVG Score: -112.14\n",
      "Episode 536, Score: -98.0 (0.01), AVG Score: -111.72\n",
      "Episode 537, Score: -113.0 (0.01), AVG Score: -111.52\n",
      "Episode 538, Score: -111.0 (0.01), AVG Score: -111.47\n",
      "Episode 539, Score: -108.0 (0.01), AVG Score: -111.42\n",
      "Episode 540, Score: -96.0 (0.01), AVG Score: -111.25\n",
      "Episode 541, Score: -84.0 (0.01), AVG Score: -110.93\n",
      "Episode 542, Score: -118.0 (0.01), AVG Score: -110.93\n",
      "Episode 543, Score: -87.0 (0.01), AVG Score: -110.13\n",
      "Episode 544, Score: -131.0 (0.01), AVG Score: -110.39\n",
      "Episode 545, Score: -107.0 (0.01), AVG Score: -110.52\n",
      "Episode 546, Score: -119.0 (0.01), AVG Score: -109.71\n",
      "Episode 547, Score: -142.0 (0.01), AVG Score: -110.04\n",
      "Episode 548, Score: -116.0 (0.01), AVG Score: -109.47\n",
      "Episode 549, Score: -109.0 (0.01), AVG Score: -108.98\n",
      "Episode 550, Score: -143.0 (0.01), AVG Score: -109.29\n",
      "Episode 551, Score: -91.0 (0.01), AVG Score: -109.14\n",
      "INFO:tensorflow:Assets written to: saved_networks/dqn_model0/assets\n",
      "Environment Solved in 552 episodes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import gym\n",
    "\n",
    "\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "spec = gym.spec(\"MountainCar-v0\")\n",
    "train = 1\n",
    "test = 0\n",
    "num_episodes = 1500\n",
    "graph = True\n",
    "\n",
    "file_type = 'tf'\n",
    "file = 'saved_networks/dqn_model20'\n",
    "\n",
    "dqn_agent = Agent(lr=0.004, discount_factor=0.99, num_actions=3, epsilon=1.0, batch_size=256, input_dims=2)\n",
    "\n",
    "for i in range(10):\n",
    "  if train and not test:\n",
    "      steps_per_episode = dqn_agent.train_model(env, num_episodes, graph)\n",
    "  else:\n",
    "      dqn_agent.test(env, num_episodes, file_type, file, graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qttnd3MLWauA",
    "outputId": "d9352f19-4974-4440-81f9-eec0948a92db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# change path here as per your directory structure\n",
    "os.chdir('drive/My Drive/CS6700/PA2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "j3XCjTbLLlKs",
    "outputId": "098282c1-c79e-47d4-f01f-df526af08176"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Steps per epsiode')\n",
    "#print(len(steps[0][0]))\n",
    "plt.plot(np.arange(len(steps_per_episode)), steps_per_episode)\n",
    "plt.savefig(fname = \"config\" + \"4_mc\" + \"_steps\", format = 'jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "RA127j6DbsjM",
    "outputId": "90b934c7-9518-4593-adf4-8e2d290b1b43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Score: -200.0 (0.9927000000000008), AVG Score: -200.0\n",
      "Episode 1, Score: -200.0 (0.972700000000003), AVG Score: -200.0\n",
      "Episode 2, Score: -200.0 (0.9527000000000052), AVG Score: -200.0\n",
      "Episode 3, Score: -200.0 (0.9327000000000074), AVG Score: -200.0\n",
      "Episode 4, Score: -200.0 (0.9127000000000096), AVG Score: -200.0\n",
      "Episode 5, Score: -200.0 (0.8927000000000118), AVG Score: -200.0\n",
      "Episode 6, Score: -200.0 (0.872700000000014), AVG Score: -200.0\n",
      "Episode 7, Score: -200.0 (0.8527000000000162), AVG Score: -200.0\n",
      "Episode 8, Score: -200.0 (0.8327000000000184), AVG Score: -200.0\n",
      "Episode 9, Score: -200.0 (0.8127000000000206), AVG Score: -200.0\n",
      "Episode 10, Score: -200.0 (0.7927000000000228), AVG Score: -200.0\n",
      "Episode 11, Score: -200.0 (0.772700000000025), AVG Score: -200.0\n",
      "Episode 12, Score: -200.0 (0.7527000000000272), AVG Score: -200.0\n",
      "Episode 13, Score: -200.0 (0.7327000000000294), AVG Score: -200.0\n",
      "Episode 14, Score: -200.0 (0.7127000000000316), AVG Score: -200.0\n",
      "Episode 15, Score: -200.0 (0.6927000000000338), AVG Score: -200.0\n",
      "Episode 16, Score: -200.0 (0.672700000000036), AVG Score: -200.0\n",
      "Episode 17, Score: -200.0 (0.6527000000000382), AVG Score: -200.0\n",
      "Episode 18, Score: -200.0 (0.6327000000000405), AVG Score: -200.0\n",
      "Episode 19, Score: -200.0 (0.6127000000000427), AVG Score: -200.0\n",
      "Episode 20, Score: -200.0 (0.5927000000000449), AVG Score: -200.0\n",
      "Episode 21, Score: -200.0 (0.5727000000000471), AVG Score: -200.0\n",
      "Episode 22, Score: -200.0 (0.5527000000000493), AVG Score: -200.0\n",
      "Episode 23, Score: -200.0 (0.5327000000000515), AVG Score: -200.0\n",
      "Episode 24, Score: -200.0 (0.5127000000000537), AVG Score: -200.0\n",
      "Episode 25, Score: -200.0 (0.49270000000005587), AVG Score: -200.0\n",
      "Episode 26, Score: -200.0 (0.4727000000000581), AVG Score: -200.0\n",
      "Episode 27, Score: -200.0 (0.4527000000000603), AVG Score: -200.0\n",
      "Episode 28, Score: -200.0 (0.4327000000000625), AVG Score: -200.0\n",
      "Episode 29, Score: -200.0 (0.4127000000000647), AVG Score: -200.0\n",
      "Episode 30, Score: -200.0 (0.3927000000000669), AVG Score: -200.0\n",
      "Episode 31, Score: -200.0 (0.3727000000000691), AVG Score: -200.0\n",
      "Episode 32, Score: -200.0 (0.3527000000000713), AVG Score: -200.0\n",
      "Episode 33, Score: -200.0 (0.3327000000000735), AVG Score: -200.0\n",
      "Episode 34, Score: -200.0 (0.3127000000000757), AVG Score: -200.0\n",
      "Episode 35, Score: -200.0 (0.2927000000000779), AVG Score: -200.0\n",
      "Episode 36, Score: -200.0 (0.2727000000000801), AVG Score: -200.0\n",
      "Episode 37, Score: -200.0 (0.2527000000000823), AVG Score: -200.0\n",
      "Episode 38, Score: -200.0 (0.2327000000000845), AVG Score: -200.0\n",
      "Episode 39, Score: -200.0 (0.2127000000000867), AVG Score: -200.0\n",
      "Episode 40, Score: -200.0 (0.1927000000000889), AVG Score: -200.0\n",
      "Episode 41, Score: -200.0 (0.17270000000009111), AVG Score: -200.0\n",
      "Episode 42, Score: -200.0 (0.15270000000009332), AVG Score: -200.0\n",
      "Episode 43, Score: -200.0 (0.13270000000009552), AVG Score: -200.0\n",
      "Episode 44, Score: -200.0 (0.11270000000009602), AVG Score: -200.0\n",
      "Episode 45, Score: -200.0 (0.09270000000009544), AVG Score: -200.0\n",
      "Episode 46, Score: -200.0 (0.07270000000009487), AVG Score: -200.0\n",
      "Episode 47, Score: -200.0 (0.052700000000094296), AVG Score: -200.0\n",
      "Episode 48, Score: -200.0 (0.032700000000093724), AVG Score: -200.0\n",
      "Episode 49, Score: -200.0 (0.012700000000093796), AVG Score: -200.0\n",
      "Episode 50, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 51, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 52, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 53, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 54, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 55, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 56, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 57, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 58, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 59, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 60, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 61, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 62, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 63, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 64, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 65, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 66, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 67, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 68, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 69, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 70, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 71, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 72, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 73, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 74, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 75, Score: -200.0 (0.01), AVG Score: -200.0\n",
      "Episode 76, Score: -146.0 (0.01), AVG Score: -199.2987012987013\n",
      "Episode 77, Score: -200.0 (0.01), AVG Score: -199.30769230769232\n",
      "Episode 78, Score: -200.0 (0.01), AVG Score: -199.31645569620252\n",
      "Episode 79, Score: -200.0 (0.01), AVG Score: -199.325\n",
      "Episode 80, Score: -200.0 (0.01), AVG Score: -199.33333333333334\n",
      "Episode 81, Score: -200.0 (0.01), AVG Score: -199.34146341463415\n",
      "Episode 82, Score: -200.0 (0.01), AVG Score: -199.34939759036143\n",
      "Episode 83, Score: -200.0 (0.01), AVG Score: -199.35714285714286\n",
      "Episode 84, Score: -200.0 (0.01), AVG Score: -199.36470588235295\n",
      "Episode 85, Score: -200.0 (0.01), AVG Score: -199.37209302325581\n",
      "Episode 86, Score: -200.0 (0.01), AVG Score: -199.3793103448276\n",
      "Episode 87, Score: -200.0 (0.01), AVG Score: -199.38636363636363\n",
      "Episode 88, Score: -200.0 (0.01), AVG Score: -199.3932584269663\n",
      "Episode 89, Score: -200.0 (0.01), AVG Score: -199.4\n",
      "Episode 90, Score: -200.0 (0.01), AVG Score: -199.4065934065934\n",
      "Episode 91, Score: -200.0 (0.01), AVG Score: -199.41304347826087\n",
      "Episode 92, Score: -200.0 (0.01), AVG Score: -199.41935483870967\n",
      "Episode 93, Score: -200.0 (0.01), AVG Score: -199.4255319148936\n",
      "Episode 94, Score: -200.0 (0.01), AVG Score: -199.43157894736842\n",
      "Episode 95, Score: -200.0 (0.01), AVG Score: -199.4375\n",
      "Episode 96, Score: -200.0 (0.01), AVG Score: -199.44329896907217\n",
      "Episode 97, Score: -200.0 (0.01), AVG Score: -199.44897959183675\n",
      "Episode 98, Score: -200.0 (0.01), AVG Score: -199.45454545454547\n",
      "Episode 99, Score: -200.0 (0.01), AVG Score: -199.46\n",
      "Episode 100, Score: -200.0 (0.01), AVG Score: -199.46\n",
      "Episode 101, Score: -200.0 (0.01), AVG Score: -199.46\n",
      "Episode 102, Score: -200.0 (0.01), AVG Score: -199.46\n",
      "Episode 103, Score: -200.0 (0.01), AVG Score: -199.46\n",
      "Episode 104, Score: -200.0 (0.01), AVG Score: -199.46\n",
      "Episode 105, Score: -200.0 (0.01), AVG Score: -199.46\n",
      "Episode 106, Score: -200.0 (0.01), AVG Score: -199.46\n",
      "Episode 107, Score: -200.0 (0.01), AVG Score: -199.46\n",
      "Episode 108, Score: -158.0 (0.01), AVG Score: -199.04\n",
      "Episode 109, Score: -200.0 (0.01), AVG Score: -199.04\n",
      "Episode 110, Score: -200.0 (0.01), AVG Score: -199.04\n",
      "Episode 111, Score: -168.0 (0.01), AVG Score: -198.72\n",
      "Episode 112, Score: -156.0 (0.01), AVG Score: -198.28\n",
      "Episode 113, Score: -125.0 (0.01), AVG Score: -197.53\n",
      "Episode 114, Score: -193.0 (0.01), AVG Score: -197.46\n",
      "Episode 115, Score: -200.0 (0.01), AVG Score: -197.46\n",
      "Episode 116, Score: -200.0 (0.01), AVG Score: -197.46\n",
      "Episode 117, Score: -200.0 (0.01), AVG Score: -197.46\n",
      "Episode 118, Score: -138.0 (0.01), AVG Score: -196.84\n",
      "Episode 119, Score: -151.0 (0.01), AVG Score: -196.35\n",
      "Episode 120, Score: -200.0 (0.01), AVG Score: -196.35\n",
      "Episode 121, Score: -179.0 (0.01), AVG Score: -196.14\n",
      "Episode 122, Score: -156.0 (0.01), AVG Score: -195.7\n",
      "Episode 123, Score: -126.0 (0.01), AVG Score: -194.96\n",
      "Episode 124, Score: -200.0 (0.01), AVG Score: -194.96\n",
      "Episode 125, Score: -123.0 (0.01), AVG Score: -194.19\n",
      "Episode 126, Score: -142.0 (0.01), AVG Score: -193.61\n",
      "Episode 127, Score: -182.0 (0.01), AVG Score: -193.43\n",
      "Episode 128, Score: -200.0 (0.01), AVG Score: -193.43\n",
      "Episode 129, Score: -181.0 (0.01), AVG Score: -193.24\n",
      "Episode 130, Score: -200.0 (0.01), AVG Score: -193.24\n",
      "Episode 131, Score: -200.0 (0.01), AVG Score: -193.24\n",
      "Episode 132, Score: -147.0 (0.01), AVG Score: -192.71\n",
      "Episode 133, Score: -187.0 (0.01), AVG Score: -192.58\n",
      "Episode 134, Score: -182.0 (0.01), AVG Score: -192.4\n",
      "Episode 135, Score: -197.0 (0.01), AVG Score: -192.37\n",
      "Episode 136, Score: -153.0 (0.01), AVG Score: -191.9\n",
      "Episode 137, Score: -191.0 (0.01), AVG Score: -191.81\n",
      "Episode 138, Score: -140.0 (0.01), AVG Score: -191.21\n",
      "Episode 139, Score: -150.0 (0.01), AVG Score: -190.71\n",
      "Episode 140, Score: -168.0 (0.01), AVG Score: -190.39\n",
      "Episode 141, Score: -141.0 (0.01), AVG Score: -189.8\n",
      "Episode 142, Score: -170.0 (0.01), AVG Score: -189.5\n",
      "Episode 143, Score: -151.0 (0.01), AVG Score: -189.01\n",
      "Episode 144, Score: -200.0 (0.01), AVG Score: -189.01\n",
      "Episode 145, Score: -200.0 (0.01), AVG Score: -189.01\n",
      "Episode 146, Score: -164.0 (0.01), AVG Score: -188.65\n",
      "Episode 147, Score: -200.0 (0.01), AVG Score: -188.65\n",
      "Episode 148, Score: -182.0 (0.01), AVG Score: -188.47\n",
      "Episode 149, Score: -87.0 (0.01), AVG Score: -187.34\n",
      "Episode 150, Score: -154.0 (0.01), AVG Score: -186.88\n",
      "Episode 151, Score: -125.0 (0.01), AVG Score: -186.13\n",
      "Episode 152, Score: -200.0 (0.01), AVG Score: -186.13\n",
      "Episode 153, Score: -87.0 (0.01), AVG Score: -185.0\n",
      "Episode 154, Score: -111.0 (0.01), AVG Score: -184.11\n",
      "Episode 155, Score: -159.0 (0.01), AVG Score: -183.7\n",
      "Episode 156, Score: -195.0 (0.01), AVG Score: -183.65\n",
      "Episode 157, Score: -96.0 (0.01), AVG Score: -182.61\n",
      "Episode 158, Score: -162.0 (0.01), AVG Score: -182.23\n",
      "Episode 159, Score: -174.0 (0.01), AVG Score: -181.97\n",
      "Episode 160, Score: -161.0 (0.01), AVG Score: -181.58\n",
      "Episode 161, Score: -141.0 (0.01), AVG Score: -180.99\n",
      "Episode 162, Score: -153.0 (0.01), AVG Score: -180.52\n",
      "Episode 163, Score: -123.0 (0.01), AVG Score: -179.75\n",
      "Episode 164, Score: -125.0 (0.01), AVG Score: -179.0\n",
      "Episode 165, Score: -156.0 (0.01), AVG Score: -178.56\n",
      "Episode 166, Score: -200.0 (0.01), AVG Score: -178.56\n",
      "Episode 167, Score: -147.0 (0.01), AVG Score: -178.03\n",
      "Episode 168, Score: -170.0 (0.01), AVG Score: -177.73\n",
      "Episode 169, Score: -95.0 (0.01), AVG Score: -176.68\n",
      "Episode 170, Score: -125.0 (0.01), AVG Score: -175.93\n",
      "Episode 171, Score: -131.0 (0.01), AVG Score: -175.24\n",
      "Episode 172, Score: -164.0 (0.01), AVG Score: -174.88\n",
      "Episode 173, Score: -105.0 (0.01), AVG Score: -173.93\n",
      "Episode 174, Score: -147.0 (0.01), AVG Score: -173.4\n",
      "Episode 175, Score: -132.0 (0.01), AVG Score: -172.72\n",
      "Episode 176, Score: -129.0 (0.01), AVG Score: -172.55\n",
      "Episode 177, Score: -94.0 (0.01), AVG Score: -171.49\n",
      "Episode 178, Score: -143.0 (0.01), AVG Score: -170.92\n",
      "Episode 179, Score: -166.0 (0.01), AVG Score: -170.58\n",
      "Episode 180, Score: -173.0 (0.01), AVG Score: -170.31\n",
      "Episode 181, Score: -140.0 (0.01), AVG Score: -169.71\n",
      "Episode 182, Score: -97.0 (0.01), AVG Score: -168.68\n",
      "Episode 183, Score: -163.0 (0.01), AVG Score: -168.31\n",
      "Episode 184, Score: -115.0 (0.01), AVG Score: -167.46\n",
      "Episode 185, Score: -96.0 (0.01), AVG Score: -166.42\n",
      "Episode 186, Score: -177.0 (0.01), AVG Score: -166.19\n",
      "Episode 187, Score: -174.0 (0.01), AVG Score: -165.93\n",
      "Episode 188, Score: -164.0 (0.01), AVG Score: -165.57\n",
      "Episode 189, Score: -152.0 (0.01), AVG Score: -165.09\n",
      "Episode 190, Score: -112.0 (0.01), AVG Score: -164.21\n",
      "Episode 191, Score: -170.0 (0.01), AVG Score: -163.91\n",
      "Episode 192, Score: -110.0 (0.01), AVG Score: -163.01\n",
      "Episode 193, Score: -128.0 (0.01), AVG Score: -162.29\n",
      "Episode 194, Score: -130.0 (0.01), AVG Score: -161.59\n",
      "Episode 195, Score: -114.0 (0.01), AVG Score: -160.73\n",
      "Episode 196, Score: -121.0 (0.01), AVG Score: -159.94\n",
      "Episode 197, Score: -117.0 (0.01), AVG Score: -159.11\n",
      "Episode 198, Score: -157.0 (0.01), AVG Score: -158.68\n",
      "Episode 199, Score: -115.0 (0.01), AVG Score: -157.83\n",
      "Episode 200, Score: -115.0 (0.01), AVG Score: -156.98\n",
      "Episode 201, Score: -91.0 (0.01), AVG Score: -155.89\n",
      "Episode 202, Score: -155.0 (0.01), AVG Score: -155.44\n",
      "Episode 203, Score: -96.0 (0.01), AVG Score: -154.4\n",
      "Episode 204, Score: -154.0 (0.01), AVG Score: -153.94\n",
      "Episode 205, Score: -126.0 (0.01), AVG Score: -153.2\n",
      "Episode 206, Score: -114.0 (0.01), AVG Score: -152.34\n",
      "Episode 207, Score: -113.0 (0.01), AVG Score: -151.47\n",
      "Episode 208, Score: -106.0 (0.01), AVG Score: -150.95\n",
      "Episode 209, Score: -92.0 (0.01), AVG Score: -149.87\n",
      "Episode 210, Score: -96.0 (0.01), AVG Score: -148.83\n",
      "Episode 211, Score: -159.0 (0.01), AVG Score: -148.74\n",
      "Episode 212, Score: -160.0 (0.01), AVG Score: -148.78\n",
      "Episode 213, Score: -123.0 (0.01), AVG Score: -148.76\n",
      "Episode 214, Score: -153.0 (0.01), AVG Score: -148.36\n",
      "Episode 215, Score: -183.0 (0.01), AVG Score: -148.19\n",
      "Episode 216, Score: -95.0 (0.01), AVG Score: -147.14\n",
      "Episode 217, Score: -132.0 (0.01), AVG Score: -146.46\n",
      "Episode 218, Score: -200.0 (0.01), AVG Score: -147.08\n",
      "Episode 219, Score: -110.0 (0.01), AVG Score: -146.67\n",
      "Episode 220, Score: -91.0 (0.01), AVG Score: -145.58\n",
      "Episode 221, Score: -134.0 (0.01), AVG Score: -145.13\n",
      "Episode 222, Score: -161.0 (0.01), AVG Score: -145.18\n",
      "Episode 223, Score: -166.0 (0.01), AVG Score: -145.58\n",
      "Episode 224, Score: -153.0 (0.01), AVG Score: -145.11\n",
      "Episode 225, Score: -136.0 (0.01), AVG Score: -145.24\n",
      "Episode 226, Score: -148.0 (0.01), AVG Score: -145.3\n",
      "Episode 227, Score: -97.0 (0.01), AVG Score: -144.45\n",
      "Episode 228, Score: -111.0 (0.01), AVG Score: -143.56\n",
      "Episode 229, Score: -150.0 (0.01), AVG Score: -143.25\n",
      "Episode 230, Score: -115.0 (0.01), AVG Score: -142.4\n",
      "Episode 231, Score: -100.0 (0.01), AVG Score: -141.4\n",
      "Episode 232, Score: -180.0 (0.01), AVG Score: -141.73\n",
      "Episode 233, Score: -159.0 (0.01), AVG Score: -141.45\n",
      "Episode 234, Score: -155.0 (0.01), AVG Score: -141.18\n",
      "Episode 235, Score: -131.0 (0.01), AVG Score: -140.52\n",
      "Episode 236, Score: -115.0 (0.01), AVG Score: -140.14\n",
      "Episode 237, Score: -124.0 (0.01), AVG Score: -139.47\n",
      "Episode 238, Score: -124.0 (0.01), AVG Score: -139.31\n",
      "Episode 239, Score: -105.0 (0.01), AVG Score: -138.86\n",
      "Episode 240, Score: -111.0 (0.01), AVG Score: -138.29\n",
      "Episode 241, Score: -116.0 (0.01), AVG Score: -138.04\n",
      "Episode 242, Score: -140.0 (0.01), AVG Score: -137.74\n",
      "Episode 243, Score: -117.0 (0.01), AVG Score: -137.4\n",
      "Episode 244, Score: -173.0 (0.01), AVG Score: -137.13\n",
      "Episode 245, Score: -136.0 (0.01), AVG Score: -136.49\n",
      "Episode 246, Score: -104.0 (0.01), AVG Score: -135.89\n",
      "Episode 247, Score: -123.0 (0.01), AVG Score: -135.12\n",
      "Episode 248, Score: -98.0 (0.01), AVG Score: -134.28\n",
      "Episode 249, Score: -152.0 (0.01), AVG Score: -134.93\n",
      "Episode 250, Score: -160.0 (0.01), AVG Score: -134.99\n",
      "Episode 251, Score: -136.0 (0.01), AVG Score: -135.1\n",
      "Episode 252, Score: -125.0 (0.01), AVG Score: -134.35\n",
      "Episode 253, Score: -116.0 (0.01), AVG Score: -134.64\n",
      "Episode 254, Score: -119.0 (0.01), AVG Score: -134.72\n",
      "Episode 255, Score: -101.0 (0.01), AVG Score: -134.14\n",
      "Episode 256, Score: -142.0 (0.01), AVG Score: -133.61\n",
      "Episode 257, Score: -146.0 (0.01), AVG Score: -134.11\n",
      "Episode 258, Score: -118.0 (0.01), AVG Score: -133.67\n",
      "Episode 259, Score: -141.0 (0.01), AVG Score: -133.34\n",
      "Episode 260, Score: -181.0 (0.01), AVG Score: -133.54\n",
      "Episode 261, Score: -104.0 (0.01), AVG Score: -133.17\n",
      "Episode 262, Score: -116.0 (0.01), AVG Score: -132.8\n",
      "Episode 263, Score: -144.0 (0.01), AVG Score: -133.01\n",
      "Episode 264, Score: -147.0 (0.01), AVG Score: -133.23\n",
      "Episode 265, Score: -161.0 (0.01), AVG Score: -133.28\n",
      "Episode 266, Score: -108.0 (0.01), AVG Score: -132.36\n",
      "Episode 267, Score: -146.0 (0.01), AVG Score: -132.35\n",
      "Episode 268, Score: -114.0 (0.01), AVG Score: -131.79\n",
      "Episode 269, Score: -85.0 (0.01), AVG Score: -131.69\n",
      "Episode 270, Score: -151.0 (0.01), AVG Score: -131.95\n",
      "Episode 271, Score: -161.0 (0.01), AVG Score: -132.25\n",
      "Episode 272, Score: -129.0 (0.01), AVG Score: -131.9\n",
      "Episode 273, Score: -147.0 (0.01), AVG Score: -132.32\n",
      "Episode 274, Score: -110.0 (0.01), AVG Score: -131.95\n",
      "Episode 275, Score: -157.0 (0.01), AVG Score: -132.2\n",
      "Episode 276, Score: -148.0 (0.01), AVG Score: -132.39\n",
      "Episode 277, Score: -118.0 (0.01), AVG Score: -132.63\n",
      "Episode 278, Score: -117.0 (0.01), AVG Score: -132.37\n",
      "Episode 279, Score: -148.0 (0.01), AVG Score: -132.19\n",
      "Episode 280, Score: -139.0 (0.01), AVG Score: -131.85\n",
      "Episode 281, Score: -123.0 (0.01), AVG Score: -131.68\n",
      "Episode 282, Score: -161.0 (0.01), AVG Score: -132.32\n",
      "Episode 283, Score: -168.0 (0.01), AVG Score: -132.37\n",
      "Episode 284, Score: -162.0 (0.01), AVG Score: -132.84\n",
      "Episode 285, Score: -109.0 (0.01), AVG Score: -132.97\n",
      "Episode 286, Score: -156.0 (0.01), AVG Score: -132.76\n",
      "Episode 287, Score: -113.0 (0.01), AVG Score: -132.15\n",
      "Episode 288, Score: -90.0 (0.01), AVG Score: -131.41\n",
      "Episode 289, Score: -117.0 (0.01), AVG Score: -131.06\n",
      "Episode 290, Score: -117.0 (0.01), AVG Score: -131.11\n",
      "Episode 291, Score: -109.0 (0.01), AVG Score: -130.5\n",
      "Episode 292, Score: -115.0 (0.01), AVG Score: -130.55\n",
      "Episode 293, Score: -86.0 (0.01), AVG Score: -130.13\n",
      "Episode 294, Score: -86.0 (0.01), AVG Score: -129.69\n",
      "Episode 295, Score: -162.0 (0.01), AVG Score: -130.17\n",
      "Episode 296, Score: -83.0 (0.01), AVG Score: -129.79\n",
      "Episode 297, Score: -143.0 (0.01), AVG Score: -130.05\n",
      "Episode 298, Score: -107.0 (0.01), AVG Score: -129.55\n",
      "Episode 299, Score: -161.0 (0.01), AVG Score: -130.01\n",
      "Episode 300, Score: -111.0 (0.01), AVG Score: -129.97\n",
      "Episode 301, Score: -157.0 (0.01), AVG Score: -130.63\n",
      "Episode 302, Score: -181.0 (0.01), AVG Score: -130.89\n",
      "Episode 303, Score: -163.0 (0.01), AVG Score: -131.56\n",
      "Episode 304, Score: -119.0 (0.01), AVG Score: -131.21\n",
      "Episode 305, Score: -169.0 (0.01), AVG Score: -131.64\n",
      "Episode 306, Score: -163.0 (0.01), AVG Score: -132.13\n",
      "Episode 307, Score: -148.0 (0.01), AVG Score: -132.48\n",
      "Episode 308, Score: -163.0 (0.01), AVG Score: -133.05\n",
      "Episode 309, Score: -161.0 (0.01), AVG Score: -133.74\n",
      "Episode 310, Score: -151.0 (0.01), AVG Score: -134.29\n",
      "Episode 311, Score: -163.0 (0.01), AVG Score: -134.33\n",
      "Episode 312, Score: -104.0 (0.01), AVG Score: -133.77\n",
      "Episode 313, Score: -111.0 (0.01), AVG Score: -133.65\n",
      "Episode 314, Score: -154.0 (0.01), AVG Score: -133.66\n",
      "Episode 315, Score: -90.0 (0.01), AVG Score: -132.73\n",
      "Episode 316, Score: -115.0 (0.01), AVG Score: -132.93\n",
      "Episode 317, Score: -160.0 (0.01), AVG Score: -133.21\n",
      "Episode 318, Score: -106.0 (0.01), AVG Score: -132.27\n",
      "Episode 319, Score: -147.0 (0.01), AVG Score: -132.64\n",
      "Episode 320, Score: -156.0 (0.01), AVG Score: -133.29\n",
      "Episode 321, Score: -159.0 (0.01), AVG Score: -133.54\n",
      "Episode 322, Score: -171.0 (0.01), AVG Score: -133.64\n",
      "Episode 323, Score: -89.0 (0.01), AVG Score: -132.87\n",
      "Episode 324, Score: -89.0 (0.01), AVG Score: -132.23\n",
      "Episode 325, Score: -143.0 (0.01), AVG Score: -132.3\n",
      "Episode 326, Score: -87.0 (0.01), AVG Score: -131.69\n",
      "Episode 327, Score: -140.0 (0.01), AVG Score: -132.12\n",
      "Episode 328, Score: -132.0 (0.01), AVG Score: -132.33\n",
      "Episode 329, Score: -101.0 (0.01), AVG Score: -131.84\n",
      "Episode 330, Score: -170.0 (0.01), AVG Score: -132.39\n",
      "Episode 331, Score: -86.0 (0.01), AVG Score: -132.25\n",
      "Episode 332, Score: -111.0 (0.01), AVG Score: -131.56\n",
      "Episode 333, Score: -160.0 (0.01), AVG Score: -131.57\n",
      "Episode 334, Score: -94.0 (0.01), AVG Score: -130.96\n",
      "Episode 335, Score: -156.0 (0.01), AVG Score: -131.21\n",
      "Episode 336, Score: -118.0 (0.01), AVG Score: -131.24\n",
      "Episode 337, Score: -157.0 (0.01), AVG Score: -131.57\n",
      "Episode 338, Score: -166.0 (0.01), AVG Score: -131.99\n",
      "Episode 339, Score: -124.0 (0.01), AVG Score: -132.18\n",
      "Episode 340, Score: -161.0 (0.01), AVG Score: -132.68\n",
      "Episode 341, Score: -127.0 (0.01), AVG Score: -132.79\n",
      "Episode 342, Score: -139.0 (0.01), AVG Score: -132.78\n",
      "Episode 343, Score: -106.0 (0.01), AVG Score: -132.67\n",
      "Episode 344, Score: -159.0 (0.01), AVG Score: -132.53\n",
      "Episode 345, Score: -108.0 (0.01), AVG Score: -132.25\n",
      "Episode 346, Score: -114.0 (0.01), AVG Score: -132.35\n",
      "Episode 347, Score: -108.0 (0.01), AVG Score: -132.2\n",
      "Episode 348, Score: -158.0 (0.01), AVG Score: -132.8\n",
      "Episode 349, Score: -119.0 (0.01), AVG Score: -132.47\n",
      "Episode 350, Score: -109.0 (0.01), AVG Score: -131.96\n",
      "Episode 351, Score: -113.0 (0.01), AVG Score: -131.73\n",
      "Episode 352, Score: -99.0 (0.01), AVG Score: -131.47\n",
      "Episode 353, Score: -117.0 (0.01), AVG Score: -131.48\n",
      "Episode 354, Score: -107.0 (0.01), AVG Score: -131.36\n",
      "Episode 355, Score: -125.0 (0.01), AVG Score: -131.6\n",
      "Episode 356, Score: -117.0 (0.01), AVG Score: -131.35\n",
      "Episode 357, Score: -89.0 (0.01), AVG Score: -130.78\n",
      "Episode 358, Score: -147.0 (0.01), AVG Score: -131.07\n",
      "Episode 359, Score: -159.0 (0.01), AVG Score: -131.25\n",
      "Episode 360, Score: -126.0 (0.01), AVG Score: -130.7\n",
      "Episode 361, Score: -83.0 (0.01), AVG Score: -130.49\n",
      "Episode 362, Score: -141.0 (0.01), AVG Score: -130.74\n",
      "Episode 363, Score: -147.0 (0.01), AVG Score: -130.77\n",
      "Episode 364, Score: -154.0 (0.01), AVG Score: -130.84\n",
      "Episode 365, Score: -114.0 (0.01), AVG Score: -130.37\n",
      "Episode 366, Score: -91.0 (0.01), AVG Score: -130.2\n",
      "Episode 367, Score: -89.0 (0.01), AVG Score: -129.63\n",
      "Episode 368, Score: -163.0 (0.01), AVG Score: -130.12\n",
      "Episode 369, Score: -121.0 (0.01), AVG Score: -130.48\n",
      "Episode 370, Score: -109.0 (0.01), AVG Score: -130.06\n",
      "Episode 371, Score: -161.0 (0.01), AVG Score: -130.06\n",
      "Episode 372, Score: -94.0 (0.01), AVG Score: -129.71\n",
      "Episode 373, Score: -86.0 (0.01), AVG Score: -129.1\n",
      "Episode 374, Score: -163.0 (0.01), AVG Score: -129.63\n",
      "Episode 375, Score: -148.0 (0.01), AVG Score: -129.54\n",
      "Episode 376, Score: -147.0 (0.01), AVG Score: -129.53\n",
      "Episode 377, Score: -169.0 (0.01), AVG Score: -130.04\n",
      "Episode 378, Score: -149.0 (0.01), AVG Score: -130.36\n",
      "Episode 379, Score: -97.0 (0.01), AVG Score: -129.85\n",
      "Episode 380, Score: -85.0 (0.01), AVG Score: -129.31\n",
      "Episode 381, Score: -85.0 (0.01), AVG Score: -128.93\n",
      "Episode 382, Score: -164.0 (0.01), AVG Score: -128.96\n",
      "Episode 383, Score: -158.0 (0.01), AVG Score: -128.86\n",
      "Episode 384, Score: -86.0 (0.01), AVG Score: -128.1\n",
      "Episode 385, Score: -148.0 (0.01), AVG Score: -128.49\n",
      "Episode 386, Score: -174.0 (0.01), AVG Score: -128.67\n",
      "Episode 387, Score: -130.0 (0.01), AVG Score: -128.84\n",
      "Episode 388, Score: -86.0 (0.01), AVG Score: -128.8\n",
      "Episode 389, Score: -159.0 (0.01), AVG Score: -129.22\n",
      "Episode 390, Score: -157.0 (0.01), AVG Score: -129.62\n",
      "Episode 391, Score: -113.0 (0.01), AVG Score: -129.66\n",
      "Episode 392, Score: -156.0 (0.01), AVG Score: -130.07\n",
      "Episode 393, Score: -151.0 (0.01), AVG Score: -130.72\n",
      "Episode 394, Score: -157.0 (0.01), AVG Score: -131.43\n",
      "Episode 395, Score: -88.0 (0.01), AVG Score: -130.69\n",
      "Episode 396, Score: -155.0 (0.01), AVG Score: -131.41\n",
      "Episode 397, Score: -101.0 (0.01), AVG Score: -130.99\n",
      "Episode 398, Score: -87.0 (0.01), AVG Score: -130.79\n",
      "Episode 399, Score: -91.0 (0.01), AVG Score: -130.09\n",
      "Episode 400, Score: -167.0 (0.01), AVG Score: -130.65\n",
      "Episode 401, Score: -144.0 (0.01), AVG Score: -130.52\n",
      "Episode 402, Score: -166.0 (0.01), AVG Score: -130.37\n",
      "Episode 403, Score: -163.0 (0.01), AVG Score: -130.37\n",
      "Episode 404, Score: -84.0 (0.01), AVG Score: -130.02\n",
      "Episode 405, Score: -109.0 (0.01), AVG Score: -129.42\n",
      "Episode 406, Score: -115.0 (0.01), AVG Score: -128.94\n",
      "Episode 407, Score: -93.0 (0.01), AVG Score: -128.39\n",
      "Episode 408, Score: -163.0 (0.01), AVG Score: -128.39\n",
      "Episode 409, Score: -108.0 (0.01), AVG Score: -127.86\n",
      "Episode 410, Score: -119.0 (0.01), AVG Score: -127.54\n",
      "Episode 411, Score: -105.0 (0.01), AVG Score: -126.96\n",
      "Episode 412, Score: -121.0 (0.01), AVG Score: -127.13\n",
      "Episode 413, Score: -101.0 (0.01), AVG Score: -127.03\n",
      "Episode 414, Score: -109.0 (0.01), AVG Score: -126.58\n",
      "Episode 415, Score: -87.0 (0.01), AVG Score: -126.55\n",
      "Episode 416, Score: -159.0 (0.01), AVG Score: -126.99\n",
      "Episode 417, Score: -107.0 (0.01), AVG Score: -126.46\n",
      "Episode 418, Score: -147.0 (0.01), AVG Score: -126.87\n",
      "Episode 419, Score: -96.0 (0.01), AVG Score: -126.36\n",
      "Episode 420, Score: -92.0 (0.01), AVG Score: -125.72\n",
      "Episode 421, Score: -142.0 (0.01), AVG Score: -125.55\n",
      "Episode 422, Score: -119.0 (0.01), AVG Score: -125.03\n",
      "Episode 423, Score: -110.0 (0.01), AVG Score: -125.24\n",
      "Episode 424, Score: -118.0 (0.01), AVG Score: -125.53\n",
      "Episode 425, Score: -115.0 (0.01), AVG Score: -125.25\n",
      "Episode 426, Score: -157.0 (0.01), AVG Score: -125.95\n",
      "Episode 427, Score: -106.0 (0.01), AVG Score: -125.61\n",
      "Episode 428, Score: -113.0 (0.01), AVG Score: -125.42\n",
      "Episode 429, Score: -134.0 (0.01), AVG Score: -125.75\n",
      "Episode 430, Score: -122.0 (0.01), AVG Score: -125.27\n",
      "Episode 431, Score: -120.0 (0.01), AVG Score: -125.61\n",
      "Episode 432, Score: -122.0 (0.01), AVG Score: -125.72\n",
      "Episode 433, Score: -136.0 (0.01), AVG Score: -125.48\n",
      "Episode 434, Score: -157.0 (0.01), AVG Score: -126.11\n",
      "Episode 435, Score: -173.0 (0.01), AVG Score: -126.28\n",
      "Episode 436, Score: -86.0 (0.01), AVG Score: -125.96\n",
      "Episode 437, Score: -142.0 (0.01), AVG Score: -125.81\n",
      "Episode 438, Score: -154.0 (0.01), AVG Score: -125.69\n",
      "Episode 439, Score: -91.0 (0.01), AVG Score: -125.36\n",
      "Episode 440, Score: -167.0 (0.01), AVG Score: -125.42\n",
      "Episode 441, Score: -149.0 (0.01), AVG Score: -125.64\n",
      "Episode 442, Score: -145.0 (0.01), AVG Score: -125.7\n",
      "Episode 443, Score: -87.0 (0.01), AVG Score: -125.51\n",
      "Episode 444, Score: -98.0 (0.01), AVG Score: -124.9\n",
      "Episode 445, Score: -88.0 (0.01), AVG Score: -124.7\n",
      "Episode 446, Score: -100.0 (0.01), AVG Score: -124.56\n",
      "Episode 447, Score: -114.0 (0.01), AVG Score: -124.62\n",
      "Episode 448, Score: -127.0 (0.01), AVG Score: -124.31\n",
      "Episode 449, Score: -117.0 (0.01), AVG Score: -124.29\n",
      "Episode 450, Score: -143.0 (0.01), AVG Score: -124.63\n",
      "Episode 451, Score: -110.0 (0.01), AVG Score: -124.6\n",
      "Episode 452, Score: -110.0 (0.01), AVG Score: -124.71\n",
      "Episode 453, Score: -121.0 (0.01), AVG Score: -124.75\n",
      "Episode 454, Score: -107.0 (0.01), AVG Score: -124.75\n",
      "Episode 455, Score: -121.0 (0.01), AVG Score: -124.71\n",
      "Episode 456, Score: -151.0 (0.01), AVG Score: -125.05\n",
      "Episode 457, Score: -101.0 (0.01), AVG Score: -125.17\n",
      "Episode 458, Score: -102.0 (0.01), AVG Score: -124.72\n",
      "Episode 459, Score: -116.0 (0.01), AVG Score: -124.29\n",
      "Episode 460, Score: -108.0 (0.01), AVG Score: -124.11\n",
      "Episode 461, Score: -111.0 (0.01), AVG Score: -124.39\n",
      "Episode 462, Score: -111.0 (0.01), AVG Score: -124.09\n",
      "Episode 463, Score: -131.0 (0.01), AVG Score: -123.93\n",
      "Episode 464, Score: -161.0 (0.01), AVG Score: -124.0\n",
      "Episode 465, Score: -123.0 (0.01), AVG Score: -124.09\n",
      "Episode 466, Score: -87.0 (0.01), AVG Score: -124.05\n",
      "Episode 467, Score: -115.0 (0.01), AVG Score: -124.31\n",
      "Episode 468, Score: -112.0 (0.01), AVG Score: -123.8\n",
      "Episode 469, Score: -115.0 (0.01), AVG Score: -123.74\n",
      "Episode 470, Score: -111.0 (0.01), AVG Score: -123.76\n",
      "Episode 471, Score: -136.0 (0.01), AVG Score: -123.51\n",
      "Episode 472, Score: -110.0 (0.01), AVG Score: -123.67\n",
      "Episode 473, Score: -110.0 (0.01), AVG Score: -123.91\n",
      "Episode 474, Score: -159.0 (0.01), AVG Score: -123.87\n",
      "Episode 475, Score: -138.0 (0.01), AVG Score: -123.77\n",
      "Episode 476, Score: -149.0 (0.01), AVG Score: -123.79\n",
      "Episode 477, Score: -165.0 (0.01), AVG Score: -123.75\n",
      "Episode 478, Score: -153.0 (0.01), AVG Score: -123.79\n",
      "Episode 479, Score: -108.0 (0.01), AVG Score: -123.9\n",
      "Episode 480, Score: -108.0 (0.01), AVG Score: -124.13\n",
      "Episode 481, Score: -108.0 (0.01), AVG Score: -124.36\n",
      "Episode 482, Score: -168.0 (0.01), AVG Score: -124.4\n",
      "Episode 483, Score: -119.0 (0.01), AVG Score: -124.01\n",
      "Episode 484, Score: -105.0 (0.01), AVG Score: -124.2\n",
      "Episode 485, Score: -114.0 (0.01), AVG Score: -123.86\n",
      "Episode 486, Score: -131.0 (0.01), AVG Score: -123.43\n",
      "Episode 487, Score: -108.0 (0.01), AVG Score: -123.21\n",
      "Episode 488, Score: -97.0 (0.01), AVG Score: -123.32\n",
      "Episode 489, Score: -90.0 (0.01), AVG Score: -122.63\n",
      "Episode 490, Score: -95.0 (0.01), AVG Score: -122.01\n",
      "Episode 491, Score: -154.0 (0.01), AVG Score: -122.42\n",
      "Episode 492, Score: -118.0 (0.01), AVG Score: -122.04\n",
      "Episode 493, Score: -111.0 (0.01), AVG Score: -121.64\n",
      "Episode 494, Score: -110.0 (0.01), AVG Score: -121.17\n",
      "Episode 495, Score: -86.0 (0.01), AVG Score: -121.15\n",
      "Episode 496, Score: -114.0 (0.01), AVG Score: -120.74\n",
      "Episode 497, Score: -111.0 (0.01), AVG Score: -120.84\n",
      "Episode 498, Score: -118.0 (0.01), AVG Score: -121.15\n",
      "Episode 499, Score: -157.0 (0.01), AVG Score: -121.81\n",
      "Episode 500, Score: -116.0 (0.01), AVG Score: -121.3\n",
      "Episode 501, Score: -146.0 (0.01), AVG Score: -121.32\n",
      "Episode 502, Score: -112.0 (0.01), AVG Score: -120.78\n",
      "Episode 503, Score: -85.0 (0.01), AVG Score: -120.0\n",
      "Episode 504, Score: -108.0 (0.01), AVG Score: -120.24\n",
      "Episode 505, Score: -93.0 (0.01), AVG Score: -120.08\n",
      "Episode 506, Score: -118.0 (0.01), AVG Score: -120.11\n",
      "Episode 507, Score: -103.0 (0.01), AVG Score: -120.21\n",
      "Episode 508, Score: -105.0 (0.01), AVG Score: -119.63\n",
      "Episode 509, Score: -105.0 (0.01), AVG Score: -119.6\n",
      "Episode 510, Score: -173.0 (0.01), AVG Score: -120.14\n",
      "Episode 511, Score: -106.0 (0.01), AVG Score: -120.15\n",
      "Episode 512, Score: -93.0 (0.01), AVG Score: -119.87\n",
      "Episode 513, Score: -88.0 (0.01), AVG Score: -119.74\n",
      "Episode 514, Score: -109.0 (0.01), AVG Score: -119.74\n",
      "Episode 515, Score: -104.0 (0.01), AVG Score: -119.91\n",
      "Episode 516, Score: -148.0 (0.01), AVG Score: -119.8\n",
      "Episode 517, Score: -109.0 (0.01), AVG Score: -119.82\n",
      "Episode 518, Score: -108.0 (0.01), AVG Score: -119.43\n",
      "Episode 519, Score: -106.0 (0.01), AVG Score: -119.53\n",
      "Episode 520, Score: -106.0 (0.01), AVG Score: -119.67\n",
      "Episode 521, Score: -126.0 (0.01), AVG Score: -119.51\n",
      "Episode 522, Score: -123.0 (0.01), AVG Score: -119.55\n",
      "Episode 523, Score: -85.0 (0.01), AVG Score: -119.3\n",
      "Episode 524, Score: -109.0 (0.01), AVG Score: -119.21\n",
      "Episode 525, Score: -96.0 (0.01), AVG Score: -119.02\n",
      "Episode 526, Score: -107.0 (0.01), AVG Score: -118.52\n",
      "Episode 527, Score: -101.0 (0.01), AVG Score: -118.47\n",
      "Episode 528, Score: -179.0 (0.01), AVG Score: -119.13\n",
      "Episode 529, Score: -107.0 (0.01), AVG Score: -118.86\n",
      "Episode 530, Score: -166.0 (0.01), AVG Score: -119.3\n",
      "Episode 531, Score: -107.0 (0.01), AVG Score: -119.17\n",
      "Episode 532, Score: -129.0 (0.01), AVG Score: -119.24\n",
      "Episode 533, Score: -170.0 (0.01), AVG Score: -119.58\n",
      "Episode 534, Score: -114.0 (0.01), AVG Score: -119.15\n",
      "Episode 535, Score: -157.0 (0.01), AVG Score: -118.99\n",
      "Episode 536, Score: -106.0 (0.01), AVG Score: -119.19\n",
      "Episode 537, Score: -177.0 (0.01), AVG Score: -119.54\n",
      "Episode 538, Score: -86.0 (0.01), AVG Score: -118.86\n",
      "Episode 539, Score: -97.0 (0.01), AVG Score: -118.92\n",
      "Episode 540, Score: -89.0 (0.01), AVG Score: -118.14\n",
      "Episode 541, Score: -112.0 (0.01), AVG Score: -117.77\n",
      "Episode 542, Score: -105.0 (0.01), AVG Score: -117.37\n",
      "Episode 543, Score: -115.0 (0.01), AVG Score: -117.65\n",
      "Episode 544, Score: -89.0 (0.01), AVG Score: -117.56\n",
      "Episode 545, Score: -93.0 (0.01), AVG Score: -117.61\n",
      "Episode 546, Score: -108.0 (0.01), AVG Score: -117.69\n",
      "Episode 547, Score: -102.0 (0.01), AVG Score: -117.57\n",
      "Episode 548, Score: -98.0 (0.01), AVG Score: -117.28\n",
      "Episode 549, Score: -115.0 (0.01), AVG Score: -117.26\n",
      "Episode 550, Score: -106.0 (0.01), AVG Score: -116.89\n",
      "Episode 551, Score: -109.0 (0.01), AVG Score: -116.88\n",
      "Episode 552, Score: -157.0 (0.01), AVG Score: -117.35\n",
      "Episode 553, Score: -113.0 (0.01), AVG Score: -117.27\n",
      "Episode 554, Score: -152.0 (0.01), AVG Score: -117.72\n",
      "Episode 555, Score: -91.0 (0.01), AVG Score: -117.42\n",
      "Episode 556, Score: -108.0 (0.01), AVG Score: -116.99\n",
      "Episode 557, Score: -119.0 (0.01), AVG Score: -117.17\n",
      "Episode 558, Score: -139.0 (0.01), AVG Score: -117.54\n",
      "Episode 559, Score: -114.0 (0.01), AVG Score: -117.52\n",
      "Episode 560, Score: -112.0 (0.01), AVG Score: -117.56\n",
      "Episode 561, Score: -132.0 (0.01), AVG Score: -117.77\n",
      "Episode 562, Score: -105.0 (0.01), AVG Score: -117.71\n",
      "Episode 563, Score: -109.0 (0.01), AVG Score: -117.49\n",
      "Episode 564, Score: -108.0 (0.01), AVG Score: -116.96\n",
      "Episode 565, Score: -104.0 (0.01), AVG Score: -116.77\n",
      "Episode 566, Score: -108.0 (0.01), AVG Score: -116.98\n",
      "Episode 567, Score: -87.0 (0.01), AVG Score: -116.7\n",
      "Episode 568, Score: -91.0 (0.01), AVG Score: -116.49\n",
      "Episode 569, Score: -117.0 (0.01), AVG Score: -116.51\n",
      "Episode 570, Score: -110.0 (0.01), AVG Score: -116.5\n",
      "Episode 571, Score: -98.0 (0.01), AVG Score: -116.12\n",
      "Episode 572, Score: -105.0 (0.01), AVG Score: -116.07\n",
      "Episode 573, Score: -112.0 (0.01), AVG Score: -116.09\n",
      "Episode 574, Score: -188.0 (0.01), AVG Score: -116.38\n",
      "Episode 575, Score: -92.0 (0.01), AVG Score: -115.92\n",
      "Episode 576, Score: -107.0 (0.01), AVG Score: -115.5\n",
      "Episode 577, Score: -88.0 (0.01), AVG Score: -114.73\n",
      "Episode 578, Score: -103.0 (0.01), AVG Score: -114.23\n",
      "Episode 579, Score: -125.0 (0.01), AVG Score: -114.4\n",
      "Episode 580, Score: -112.0 (0.01), AVG Score: -114.44\n",
      "Episode 581, Score: -104.0 (0.01), AVG Score: -114.4\n",
      "Episode 582, Score: -102.0 (0.01), AVG Score: -113.74\n",
      "Episode 583, Score: -114.0 (0.01), AVG Score: -113.69\n",
      "Episode 584, Score: -189.0 (0.01), AVG Score: -114.53\n",
      "Episode 585, Score: -109.0 (0.01), AVG Score: -114.48\n",
      "Episode 586, Score: -88.0 (0.01), AVG Score: -114.05\n",
      "Episode 587, Score: -96.0 (0.01), AVG Score: -113.93\n",
      "Episode 588, Score: -90.0 (0.01), AVG Score: -113.86\n",
      "Episode 589, Score: -84.0 (0.01), AVG Score: -113.8\n",
      "Episode 590, Score: -102.0 (0.01), AVG Score: -113.87\n",
      "Episode 591, Score: -128.0 (0.01), AVG Score: -113.61\n",
      "Episode 592, Score: -111.0 (0.01), AVG Score: -113.54\n",
      "Episode 593, Score: -91.0 (0.01), AVG Score: -113.34\n",
      "Episode 594, Score: -95.0 (0.01), AVG Score: -113.19\n",
      "Episode 595, Score: -107.0 (0.01), AVG Score: -113.4\n",
      "Episode 596, Score: -86.0 (0.01), AVG Score: -113.12\n",
      "Episode 597, Score: -104.0 (0.01), AVG Score: -113.05\n",
      "Episode 598, Score: -110.0 (0.01), AVG Score: -112.97\n",
      "Episode 599, Score: -125.0 (0.01), AVG Score: -112.65\n",
      "Episode 600, Score: -109.0 (0.01), AVG Score: -112.58\n",
      "Episode 601, Score: -112.0 (0.01), AVG Score: -112.24\n",
      "Episode 602, Score: -83.0 (0.01), AVG Score: -111.95\n",
      "Episode 603, Score: -114.0 (0.01), AVG Score: -112.24\n",
      "Episode 604, Score: -104.0 (0.01), AVG Score: -112.2\n",
      "Episode 605, Score: -107.0 (0.01), AVG Score: -112.34\n",
      "Episode 606, Score: -89.0 (0.01), AVG Score: -112.05\n",
      "Episode 607, Score: -85.0 (0.01), AVG Score: -111.87\n",
      "Episode 608, Score: -106.0 (0.01), AVG Score: -111.88\n",
      "Episode 609, Score: -134.0 (0.01), AVG Score: -112.17\n",
      "Episode 610, Score: -164.0 (0.01), AVG Score: -112.08\n",
      "Episode 611, Score: -90.0 (0.01), AVG Score: -111.92\n",
      "Episode 612, Score: -90.0 (0.01), AVG Score: -111.89\n",
      "Episode 613, Score: -117.0 (0.01), AVG Score: -112.18\n",
      "Episode 614, Score: -104.0 (0.01), AVG Score: -112.13\n",
      "Episode 615, Score: -104.0 (0.01), AVG Score: -112.13\n",
      "Episode 616, Score: -108.0 (0.01), AVG Score: -111.73\n",
      "Episode 617, Score: -200.0 (0.01), AVG Score: -112.64\n",
      "Episode 618, Score: -99.0 (0.01), AVG Score: -112.55\n",
      "Episode 619, Score: -105.0 (0.01), AVG Score: -112.54\n",
      "Episode 620, Score: -92.0 (0.01), AVG Score: -112.4\n",
      "Episode 621, Score: -104.0 (0.01), AVG Score: -112.18\n",
      "Episode 622, Score: -111.0 (0.01), AVG Score: -112.06\n",
      "Episode 623, Score: -108.0 (0.01), AVG Score: -112.29\n",
      "Episode 624, Score: -126.0 (0.01), AVG Score: -112.46\n",
      "Episode 625, Score: -106.0 (0.01), AVG Score: -112.56\n",
      "Episode 626, Score: -99.0 (0.01), AVG Score: -112.48\n",
      "Episode 627, Score: -111.0 (0.01), AVG Score: -112.58\n",
      "Episode 628, Score: -138.0 (0.01), AVG Score: -112.17\n",
      "Episode 629, Score: -89.0 (0.01), AVG Score: -111.99\n",
      "Episode 630, Score: -145.0 (0.01), AVG Score: -111.78\n",
      "Episode 631, Score: -110.0 (0.01), AVG Score: -111.81\n",
      "Episode 632, Score: -142.0 (0.01), AVG Score: -111.94\n",
      "Episode 633, Score: -102.0 (0.01), AVG Score: -111.26\n",
      "Episode 634, Score: -108.0 (0.01), AVG Score: -111.2\n",
      "Episode 635, Score: -111.0 (0.01), AVG Score: -110.74\n",
      "Episode 636, Score: -107.0 (0.01), AVG Score: -110.75\n",
      "Episode 637, Score: -114.0 (0.01), AVG Score: -110.12\n",
      "Episode 638, Score: -111.0 (0.01), AVG Score: -110.37\n",
      "Episode 639, Score: -119.0 (0.01), AVG Score: -110.59\n",
      "Episode 640, Score: -107.0 (0.01), AVG Score: -110.77\n",
      "Episode 641, Score: -115.0 (0.01), AVG Score: -110.8\n",
      "Episode 642, Score: -110.0 (0.01), AVG Score: -110.85\n",
      "Episode 643, Score: -106.0 (0.01), AVG Score: -110.76\n",
      "Episode 644, Score: -101.0 (0.01), AVG Score: -110.88\n",
      "Episode 645, Score: -106.0 (0.01), AVG Score: -111.01\n",
      "Episode 646, Score: -120.0 (0.01), AVG Score: -111.13\n",
      "Episode 647, Score: -108.0 (0.01), AVG Score: -111.19\n",
      "Episode 648, Score: -105.0 (0.01), AVG Score: -111.26\n",
      "Episode 649, Score: -97.0 (0.01), AVG Score: -111.08\n",
      "Episode 650, Score: -117.0 (0.01), AVG Score: -111.19\n",
      "Episode 651, Score: -114.0 (0.01), AVG Score: -111.24\n",
      "Episode 652, Score: -85.0 (0.01), AVG Score: -110.52\n",
      "Episode 653, Score: -162.0 (0.01), AVG Score: -111.01\n",
      "Episode 654, Score: -124.0 (0.01), AVG Score: -110.73\n",
      "Episode 655, Score: -146.0 (0.01), AVG Score: -111.28\n",
      "Episode 656, Score: -147.0 (0.01), AVG Score: -111.67\n",
      "Episode 657, Score: -108.0 (0.01), AVG Score: -111.56\n",
      "Episode 658, Score: -87.0 (0.01), AVG Score: -111.04\n",
      "Episode 659, Score: -109.0 (0.01), AVG Score: -110.99\n",
      "Episode 660, Score: -108.0 (0.01), AVG Score: -110.95\n",
      "Episode 661, Score: -122.0 (0.01), AVG Score: -110.85\n",
      "Episode 662, Score: -113.0 (0.01), AVG Score: -110.93\n",
      "Episode 663, Score: -99.0 (0.01), AVG Score: -110.83\n",
      "Episode 664, Score: -112.0 (0.01), AVG Score: -110.87\n",
      "Episode 665, Score: -117.0 (0.01), AVG Score: -111.0\n",
      "Episode 666, Score: -148.0 (0.01), AVG Score: -111.4\n",
      "Episode 667, Score: -107.0 (0.01), AVG Score: -111.6\n",
      "Episode 668, Score: -90.0 (0.01), AVG Score: -111.59\n",
      "Episode 669, Score: -109.0 (0.01), AVG Score: -111.51\n",
      "Episode 670, Score: -111.0 (0.01), AVG Score: -111.52\n",
      "Episode 671, Score: -112.0 (0.01), AVG Score: -111.66\n",
      "Episode 672, Score: -103.0 (0.01), AVG Score: -111.64\n",
      "Episode 673, Score: -107.0 (0.01), AVG Score: -111.59\n",
      "Episode 674, Score: -107.0 (0.01), AVG Score: -110.78\n",
      "Episode 675, Score: -107.0 (0.01), AVG Score: -110.93\n",
      "Episode 676, Score: -108.0 (0.01), AVG Score: -110.94\n",
      "Episode 677, Score: -87.0 (0.01), AVG Score: -110.93\n",
      "Episode 678, Score: -113.0 (0.01), AVG Score: -111.03\n",
      "Episode 679, Score: -95.0 (0.01), AVG Score: -110.73\n",
      "Episode 680, Score: -107.0 (0.01), AVG Score: -110.68\n",
      "Episode 681, Score: -109.0 (0.01), AVG Score: -110.73\n",
      "Episode 682, Score: -107.0 (0.01), AVG Score: -110.78\n",
      "Episode 683, Score: -109.0 (0.01), AVG Score: -110.73\n",
      "Episode 684, Score: -106.0 (0.01), AVG Score: -109.9\n",
      "INFO:tensorflow:Assets written to: saved_networks/dqn_model0/assets\n",
      "Environment Solved in 685 episodes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from agent import Agent\n",
    "import gym\n",
    "\n",
    "\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "spec = gym.spec(\"MountainCar-v0\")\n",
    "train = 1\n",
    "test = 0\n",
    "num_episodes = 1500\n",
    "graph = True\n",
    "\n",
    "file_type = 'tf'\n",
    "file = 'saved_networks/dqn_model20'\n",
    "\n",
    "dqn_agent = Agent(lr=0.001, discount_factor=0.99, num_actions=3, epsilon=1.0, batch_size=128, input_dims=2)\n",
    "\n",
    "if train and not test:\n",
    "    steps_per_episode = dqn_agent.train_model(env, num_episodes, graph)\n",
    "else:\n",
    "    dqn_agent.test(env, num_episodes, file_type, file, graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "DKsTdgoWiIi6",
    "outputId": "e1c5e9a1-5f25-469b-dc17-1d80b7303012"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Steps per epsiode')\n",
    "#print(len(steps[0][0]))\n",
    "plt.plot(np.arange(len(steps_per_episode)), steps_per_episode)\n",
    "plt.savefig(fname = \"config\" + \"2_mc\" + \"_steps\", format = 'jpeg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g5IA6NRb3NoY"
   },
   "source": [
    "#Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwIU--Fm3ecV"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Installing packages for rendering the game on Colab\n",
    "'''\n",
    "\n",
    "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
    "!apt-get update > /dev/null 2>&1\n",
    "!apt-get install cmake > /dev/null 2>&1\n",
    "!pip install --upgrade setuptools 2>&1\n",
    "!pip install ez_setup > /dev/null 2>&1\n",
    "!pip install gym[atari] > /dev/null 2>&1\n",
    "!pip install git+https://github.com/tensorflow/docs > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tI9DJh7-3nE5"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCXeBk4X3pTN"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A bunch of imports, you don't have to worry about these\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple, deque\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from pyvirtualdisplay import Display\n",
    "import tensorflow as tf\n",
    "from IPython import display as ipythondisplay\n",
    "from PIL import Image\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sfcO0OMH3r3V"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Please refer to the first tutorial for more details on the specifics of environments\n",
    "We've only added important commands you might find useful for experiments.\n",
    "'''\n",
    "\n",
    "'''\n",
    "List of example environments\n",
    "(Source - https://gym.openai.com/envs/#classic_control)\n",
    "\n",
    "'Acrobot-v1'\n",
    "'CartPole-v0'\n",
    "'MountainCar-v0'\n",
    "'''\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "env.seed(0)\n",
    "\n",
    "state_shape = env.observation_space.shape[0]\n",
    "no_of_actions = env.action_space.n\n",
    "\n",
    "print(state_shape)\n",
    "print(no_of_actions)\n",
    "print(env.action_space.sample())\n",
    "print(\"----\")\n",
    "\n",
    "'''\n",
    "# Understanding State, Action, Reward Dynamics\n",
    "\n",
    "The agent decides an action to take depending on the state.\n",
    "\n",
    "The Environment keeps a variable specifically for the current state.\n",
    "- Everytime an action is passed to the environment, it calculates the new state and updates the current state variable.\n",
    "- It returns the new current state and reward for the agent to take the next action\n",
    "\n",
    "'''\n",
    "\n",
    "state = env.reset()   \n",
    "''' This returns the initial state (when environment is reset) '''\n",
    "\n",
    "print(state)\n",
    "print(\"----\")\n",
    "\n",
    "action = env.action_space.sample()  \n",
    "''' We take a random action now '''\n",
    "\n",
    "print(action)\n",
    "print(\"----\")\n",
    "\n",
    "next_state, reward, done, info = env.step(action) \n",
    "''' env.step is used to calculate new state and obtain reward based on old state and action taken  ''' \n",
    "\n",
    "print(next_state)\n",
    "print(reward)\n",
    "print(done)\n",
    "print(info)\n",
    "print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZ4ohTab3uPv"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "### Q Network & Some 'hyperparameters'\n",
    "\n",
    "QNetwork1:\n",
    "Input Layer - 4 nodes (State Shape) \\\n",
    "Hidden Layer 1 - 64 nodes \\\n",
    "Hidden Layer 2 - 64 nodes \\\n",
    "Output Layer - 2 nodes (Action Space) \\\n",
    "Optimizer - zero_grad()\n",
    "\n",
    "QNetwork2: Feel free to experiment more\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "'''\n",
    "Bunch of Hyper parameters (Which you might have to tune later **wink wink**)\n",
    "'''\n",
    "BUFFER_SIZE = int(1e5) # ''' replay buffer size '''\n",
    "BATCH_SIZE = 64         #''' minibatch size '''\n",
    "GAMMA = 0.99            #''' discount factor '''\n",
    "LR = 5e-4               #''' learning rate '''\n",
    "UPDATE_EVERY = 20       #''' how often to update the network (When Q target is present) '''\n",
    "\n",
    "\n",
    "class QNetwork1(nn.Module):\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=128, fc2_units=64):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(QNetwork1, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6WhOk2y3y1V"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque, namedtuple\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LoVBriBE308h"
   },
   "outputs": [],
   "source": [
    "rewards_dqn_epsilon = []\n",
    "rewards_dqn_softmax = []\n",
    "class TutorialAgent():\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, learning_rate = 5e-4, buffer_size = 1e5, batch_size = 64,  discount = 0.99, update_freq = 20):\n",
    "\n",
    "        ''' Agent Environment Interaction '''\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "        self.gamma = discount\n",
    "        self.batch_size = batch_size\n",
    "        self.update_freq = update_freq\n",
    "\n",
    "\n",
    "        ''' Q-Network '''\n",
    "        self.qnetwork_local = QNetwork1(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork1(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr= learning_rate)\n",
    "\n",
    "        ''' Replay memory '''\n",
    "        self.memory = ReplayBuffer(action_size = action_size, buffer_size = buffer_size, batch_size = batch_size, seed = seed)\n",
    "\n",
    "        ''' Initialize time step (for updating every UPDATE_EVERY steps)           -Needed for Q Targets '''\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "\n",
    "        ''' Save experience in replay memory '''\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        ''' If enough samples are available in memory, get random subset and learn '''\n",
    "        if len(self.memory) >= self.batch_size:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, self.gamma)\n",
    "\n",
    "        \"\"\" +Q TARGETS PRESENT \"\"\"\n",
    "        ''' Updating the Network every 'UPDATE_EVERY' steps taken '''      \n",
    "        self.t_step = (self.t_step + 1) % self.update_freq\n",
    "        if self.t_step == 0:\n",
    "\n",
    "            self.qnetwork_target.load_state_dict(self.qnetwork_local.state_dict())\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        ''' Epsilon-greedy action selection (Already Present) '''\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\" +E EXPERIENCE REPLAY PRESENT \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        ''' Get max predicted Q values (for next states) from target model'''\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "\n",
    "        ''' Compute Q targets for current states '''\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        ''' Get expected Q values from local model '''\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        ''' Compute loss '''\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "\n",
    "        ''' Minimize the loss '''\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        ''' Gradiant Clipping '''\n",
    "        \"\"\" +T TRUNCATION PRESENT \"\"\"\n",
    "        for param in self.qnetwork_local.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "            \n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9t4OXXg33Hj"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "class TutorialAgent_softmax():\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, learning_rate = 5e-4, buffer_size = 1e5, batch_size = 64,  discount = 0.99, update_freq = 20):\n",
    "\n",
    "        ''' Agent Environment Interaction '''\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "        self.gamma = discount\n",
    "        self.batch_size = batch_size\n",
    "        self.update_freq = update_freq\n",
    "\n",
    "        ''' Q-Network '''\n",
    "        self.qnetwork_local = QNetwork1(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork1(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr= learning_rate)\n",
    "\n",
    "        ''' Replay memory '''\n",
    "        self.memory = ReplayBuffer(action_size = action_size, buffer_size = buffer_size, batch_size = batch_size, seed = seed)\n",
    "\n",
    "        ''' Initialize time step (for updating every UPDATE_EVERY steps)           -Needed for Q Targets '''\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "\n",
    "        ''' Save experience in replay memory '''\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        ''' If enough samples are available in memory, get random subset and learn '''\n",
    "        if len(self.memory) >= self.batch_size:\n",
    "            experiences = self.memory.sample()\n",
    "            self.learn(experiences, self.gamma)\n",
    "\n",
    "        \"\"\" +Q TARGETS PRESENT \"\"\"\n",
    "        ''' Updating the Network every 'UPDATE_EVERY' steps taken '''      \n",
    "        self.t_step = (self.t_step + 1) % self.update_freq\n",
    "        if self.t_step == 0:\n",
    "\n",
    "            self.qnetwork_target.load_state_dict(self.qnetwork_local.state_dict())\n",
    "\n",
    "    def act(self, state, temp = 1):\n",
    "\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        ''' softmax action selection (newly implementing) '''\n",
    "        #print(action_values.cpu().data.numpy().shape)\n",
    "        prob = np.nan_to_num(softmax(action_values.cpu().data.numpy()[0]/temp))\n",
    "        prob /= prob.sum()\n",
    "        return np.random.choice(self.action_size, p = prob)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\" +E EXPERIENCE REPLAY PRESENT \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        ''' Get max predicted Q values (for next states) from target model'''\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "\n",
    "        ''' Compute Q targets for current states '''\n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        ''' Get expected Q values from local model '''\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        ''' Compute loss '''\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "\n",
    "        ''' Minimize the loss '''\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        ''' Gradiant Clipping '''\n",
    "        \"\"\" +T TRUNCATION PRESENT \"\"\"\n",
    "        for param in self.qnetwork_local.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "            \n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "myiq52Cu342F"
   },
   "outputs": [],
   "source": [
    "def dqn_epsilon(env, n_episodes=10000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995, learning_rate = 5e-4, buffer_size = 1e5, batch_size = 64,  discount = 0.99, update_freq = 20, target = -90):\n",
    "\n",
    "    state_shape = env.observation_space.shape[0]\n",
    "    action_shape = env.action_space.n\n",
    "    agent = TutorialAgent(state_size=state_shape,action_size = action_shape,seed = 0, learning_rate = learning_rate, buffer_size = buffer_size, batch_size = batch_size,  discount = discount, update_freq = update_freq)\n",
    "\n",
    "    scores = []                 \n",
    "    steps_per_episode = []\n",
    "    ''' list containing scores from each episode '''\n",
    "\n",
    "    scores_window_printing = deque(maxlen=10) \n",
    "    ''' For printing in the graph '''\n",
    "    \n",
    "    scores_window= deque(maxlen=100)  \n",
    "    ''' last 100 scores for checking if the avg is more than 195 '''\n",
    "\n",
    "    eps = eps_start                    \n",
    "    ''' initialize epsilon '''\n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "              steps_per_episode.append(t+1)\n",
    "              break \n",
    "        \n",
    "        if(len(steps_per_episode)!=i_episode):\n",
    "          steps_per_episode.append(max_t)\n",
    "        scores_window.append(score)       \n",
    "        scores_window_printing.append(score)   \n",
    "        ''' save most recent score '''           \n",
    "\n",
    "        eps = max(eps_end, eps_decay*eps) \n",
    "        ''' decrease epsilon '''\n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")  \n",
    "        \n",
    "        scores.append(np.mean(scores_window_printing))        \n",
    "        if i_episode % 100 == 0: \n",
    "           print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>= target:\n",
    "           print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "           break\n",
    "    return [np.array(scores),i_episode-100,steps_per_episode]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CVcUGmF39Jg"
   },
   "outputs": [],
   "source": [
    "def dqn_softmax(env, n_episodes=10000, max_t=1000, temp_start= 10000, temp_end=1, temp_decay=0.995, learning_rate = 5e-4, buffer_size = 1e5, batch_size = 64,  discount = 0.99, update_freq = 20, target = -90):\n",
    "\n",
    "    state_shape = env.observation_space.shape[0]\n",
    "    action_shape = env.action_space.n\n",
    "    agent = TutorialAgent_softmax(state_size=state_shape,action_size = action_shape,seed = 0, learning_rate = learning_rate, buffer_size = buffer_size, batch_size = batch_size,  discount = discount, update_freq = update_freq)\n",
    "    \n",
    "    scores = []              \n",
    "    steps_per_episode = [] \n",
    "\n",
    "    ''' list containing scores from each episode '''\n",
    "\n",
    "    scores_window_printing = deque(maxlen=10) \n",
    "    ''' For printing in the graph '''\n",
    "    \n",
    "    scores_window= deque(maxlen=100)  \n",
    "    ''' last 100 scores for checking if the avg is more than 195 '''\n",
    "\n",
    "    temp = temp_start                    \n",
    "    ''' initialize epsilon '''\n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        state = env.reset()\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, temp)\n",
    "            #print(action)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                steps_per_episode.append(t+1)\n",
    "                break \n",
    "        \n",
    "        if(len(steps_per_episode) != i_episode):\n",
    "          steps_per_episode.append(max_t)\n",
    "        scores_window.append(score)       \n",
    "        scores_window_printing.append(score)   \n",
    "        ''' save most recent score '''           \n",
    "\n",
    "        temp = temp*temp_decay\n",
    "        ''' decrease epsilon '''\n",
    "\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")  \n",
    "        \n",
    "        scores.append(np.mean(scores_window_printing))        \n",
    "        if i_episode % 100 == 0: \n",
    "           print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>= target:\n",
    "           print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "           break\n",
    "    return [np.array(scores),i_episode-100,steps_per_episode]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yctdccwJ39Ez"
   },
   "outputs": [],
   "source": [
    "def dqn(env, exploration = 'softmax', n_episodes = 10000,  max_t = 1000, hyp_start= 10000, hyp_end=1, hyp_decay=0.995, learning_rate = 5e-4, buffer_size = int(1e5), batch_size = 64,  discount = 0.99, update_freq = 20,target = -90):\n",
    "  if(exploration == 'epsilon'):\n",
    "    scores, num_episodes, steps_per_episode = dqn_epsilon(env, n_episodes = n_episodes, max_t = max_t, eps_start= hyp_start, eps_end = hyp_end, eps_decay = hyp_decay, learning_rate= learning_rate, buffer_size = buffer_size, batch_size = batch_size,  discount = discount, update_freq = update_freq)\n",
    "    return scores, num_episodes, steps_per_episode\n",
    "  \n",
    "  else:\n",
    "    scores, num_episodes,steps_per_episode = dqn_softmax(env, n_episodes = n_episodes, max_t = max_t, temp_start= hyp_start, temp_end = hyp_end, temp_decay = hyp_decay, learning_rate= learning_rate, buffer_size = buffer_size, batch_size = batch_size,  discount = discount, update_freq = update_freq)\n",
    "    return scores, num_episodes,steps_per_episode\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SgMN2gNB4AlP"
   },
   "outputs": [],
   "source": [
    "env2 = gym.make('Acrobot-v1')\n",
    "episodes_per_run =[]\n",
    "steps = []\n",
    "rewards_avg = []\n",
    "actual_rewards = []\n",
    "\n",
    "\n",
    "for i1 in range(10):\n",
    "  steps1 = []\n",
    "  plt.xlabel('Episodes')\n",
    "  plt.ylabel('Average_score')\n",
    "  [scores, num_episodes, steps_per_episode] = dqn(env2, exploration = 'epsilon',learning_rate = 0.001, hyp_start = 1, hyp_decay = 0.995,hyp_end = 0.001,update_freq = 100, buffer_size = int(2e5))\n",
    "  episodes_per_run.append(num_episodes)\n",
    "  actual_rewards.append(scores)\n",
    "  steps.append(steps_per_episode)\n",
    "  y_axis = []\n",
    "  n_ep = len(scores)\n",
    "  for i in range(len(scores)):\n",
    "    idx = min(99,i)\n",
    "    y_axis.append(np.mean(scores[i-idx:i+1]))\n",
    "    \n",
    "  plt.plot(np.arange(len(y_axis)) ,y_axis)\n",
    "  rewards_avg.append(y_axis)\n",
    "\n",
    "  plt.savefig(fname = \"acrobot1 \" + \"run \" + str(i1),format = 'jpeg')\n",
    "  #steps.append(steps1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frR4pYmo4JLd"
   },
   "outputs": [],
   "source": [
    "np.save('acrobot1_arr', actual_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0Oq5X6x4K_L"
   },
   "outputs": [],
   "source": [
    "y_axis_f = []\n",
    "mn = np.min(episodes_per_run)\n",
    "for i in range(mn):\n",
    "  total = 0\n",
    "  for j in rewards_avg:\n",
    "    total += j[i]\n",
    "  y_axis_f.append(total)\n",
    "\n",
    "plt.plot(np.arange(mn),y_axis_f)\n",
    "plt.xlabel('Rewards')\n",
    "plt.ylabel('Episodes')\n",
    "plt.savefig(fname = 'acrobot_ avg 1', format = 'jpeg')\n",
    "plt.show()\n",
    "\n",
    "print('Avg number of episodes req = {}'.format(np.mean(episodes_per_run)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mCCJTTMp4Lox"
   },
   "outputs": [],
   "source": [
    "arr = np.load('acrobot1_arr.npy',allow_pickle=True)\n",
    "print('for cartpole_1')\n",
    "cnt = 0\n",
    "for rewards in arr:\n",
    "  cnt = cnt + 1\n",
    "  print('Taking running avg of 100')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-99)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 100')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_1 run {} 100 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_1 run {} 100 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 10')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-9)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_1 run {} 10 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_1 run {} 10 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 1')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_1 run {} 1 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_1 run {} 1 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S8YXUPw04NbE"
   },
   "outputs": [],
   "source": [
    "env2 = gym.make('Acrobot-v1')\n",
    "episodes_per_run =[]\n",
    "steps = []\n",
    "rewards_avg = []\n",
    "actual_rewards = []\n",
    "\n",
    "\n",
    "for i1 in range(10):\n",
    "  steps1 = []\n",
    "  plt.xlabel('Episodes')\n",
    "  plt.ylabel('Average_score')\n",
    "  [scores, num_episodes, steps_per_episode] = dqn(env2, exploration = 'epsilon',learning_rate = 0.001, hyp_start = 1, hyp_decay = 0.995,hyp_end = 0.001,update_freq = 50, buffer_size = int(2e5),batch_size = 128)\n",
    "  episodes_per_run.append(num_episodes)\n",
    "  actual_rewards.append(scores)\n",
    "  steps.append(steps_per_episode)\n",
    "  y_axis = []\n",
    "  n_ep = len(scores)\n",
    "  for i in range(len(scores)):\n",
    "    idx = min(99,i)\n",
    "    y_axis.append(np.mean(scores[i-idx:i+1]))\n",
    "    \n",
    "  plt.plot(np.arange(len(y_axis)) ,y_axis)\n",
    "  rewards_avg.append(y_axis)\n",
    "\n",
    "  plt.savefig(fname = \"acrobot2 \" + \"run \" + str(i1),format = 'jpeg')\n",
    "  #steps.append(steps1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMmJVy5-4Pe1"
   },
   "outputs": [],
   "source": [
    "y_axis_f = []\n",
    "mn = np.min(episodes_per_run)\n",
    "for i in range(mn):\n",
    "  total = 0\n",
    "  for j in rewards_avg:\n",
    "    total += j[i]\n",
    "  y_axis_f.append(total)\n",
    "\n",
    "plt.plot(np.arange(mn),y_axis_f)\n",
    "plt.xlabel('Rewards')\n",
    "plt.ylabel('Episodes')\n",
    "plt.savefig(fname = 'acrobot_ avg 2', format = 'jpeg')\n",
    "plt.show()\n",
    "\n",
    "print('Avg number of episodes req = {}'.format(np.mean(episodes_per_run)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1YUP87U4Ta2"
   },
   "outputs": [],
   "source": [
    "np.save('acrobot2_arr', actual_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5HDb85t4VOz"
   },
   "outputs": [],
   "source": [
    "arr = np.load('acrobot2_arr.npy',allow_pickle=True)\n",
    "print('for acrobot_2')\n",
    "cnt = 0\n",
    "for rewards in arr:\n",
    "  cnt = cnt + 1\n",
    "  print('Taking running avg of 100')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-99)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 100')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_2 run {} 100 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_2 run {} 100 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 10')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-9)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_2 run {} 10 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_2 run {} 10 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 1')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_2 run {} 1 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_2 run {} 1 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaNoNPSu4YO_"
   },
   "outputs": [],
   "source": [
    "\n",
    "env2 = gym.make('Acrobot-v1')\n",
    "episodes_per_run =[]\n",
    "steps = []\n",
    "rewards_avg = []\n",
    "actual_rewards = []\n",
    "\n",
    "\n",
    "for i1 in range(10):\n",
    "  steps1 = []\n",
    "  plt.xlabel('Episodes')\n",
    "  plt.ylabel('Average_score')\n",
    "  [scores, num_episodes, steps_per_episode] = dqn(env2, exploration = 'epsilon',learning_rate = 0.001, hyp_start = 1, hyp_decay = 0.995,hyp_end = 0.001,update_freq = 100, buffer_size = int(2e5),batch_size = 128)\n",
    "  actual_rewards.append(scores)\n",
    "  steps.append(steps_per_episode)\n",
    "  y_axis = []\n",
    "  n_ep = len(scores)\n",
    "  for i in range(len(scores)):\n",
    "    idx = min(99,i)\n",
    "    y_axis.append(np.mean(scores[i-idx:i+1]))\n",
    "    \n",
    "  plt.plot(np.arange(len(y_axis)) ,y_axis)\n",
    "  rewards_avg.append(y_axis)\n",
    "\n",
    "  plt.savefig(fname = \"acrobot3 \" + \"run \" + str(i1),format = 'jpeg')\n",
    "  #steps.append(steps1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEsvxu0M4blV"
   },
   "outputs": [],
   "source": [
    "y_axis_f = []\n",
    "#mn = np.min(episodes_per_run[0:-2])\n",
    "mn = 443\n",
    "for i in range(mn):\n",
    "  total = 0\n",
    "  for j in rewards_avg:\n",
    "    total += j[i]\n",
    "  y_axis_f.append(total)\n",
    "\n",
    "plt.plot(np.arange(mn),y_axis_f)\n",
    "plt.xlabel('Rewards')\n",
    "plt.ylabel('Episodes')\n",
    "plt.savefig(fname = 'acrobot_ avg 3', format = 'jpeg')\n",
    "plt.show()\n",
    "\n",
    "print('Avg number of episodes req = {}'.format(446))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYeOp-eQ4eGf"
   },
   "outputs": [],
   "source": [
    "np.save('acrobot3_arr', actual_rewards)\n",
    "\n",
    "arr = np.load('acrobot3_arr.npy',allow_pickle=True)\n",
    "print('for acrobot_3')\n",
    "cnt = 0\n",
    "for rewards in arr:\n",
    "  cnt = cnt + 1\n",
    "  print('Taking running avg of 100')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-99)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 100')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_3 run {} 100 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_3 run {} 100 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 10')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-9)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_3 run {} 10 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_3 run {} 10 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 1')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_3 run {} 1 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_3 run {} 1 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JsyZ7a_Y4gvq"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "env2 = gym.make('Acrobot-v1')\n",
    "episodes_per_run =[]\n",
    "steps = []\n",
    "rewards_avg = []\n",
    "actual_rewards = []\n",
    "\n",
    "\n",
    "for i1 in range(10):\n",
    "  steps1 = []\n",
    "  plt.xlabel('Episodes')\n",
    "  plt.ylabel('Average_score')\n",
    "  [scores, num_episodes, steps_per_episode] = dqn(env2, exploration = 'epsilon',learning_rate = 0.003, hyp_start = 1, hyp_decay = 0.995,hyp_end = 0.001,update_freq = 75, buffer_size = int(2e5),batch_size = 128)\n",
    "  episodes_per_run.append(num_episodes)\n",
    "  actual_rewards.append(scores)\n",
    "  steps.append(steps_per_episode)\n",
    "  y_axis = []\n",
    "  n_ep = len(scores)\n",
    "  for i in range(len(scores)):\n",
    "    idx = min(99,i)\n",
    "    y_axis.append(np.mean(scores[i-idx:i+1]))\n",
    "    \n",
    "  plt.plot(np.arange(len(y_axis)) ,y_axis)\n",
    "  rewards_avg.append(y_axis)\n",
    "\n",
    "  plt.savefig(fname = \"acrobot4 \" + \"run \" + str(i1),format = 'jpeg')\n",
    "  #steps.append(steps1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vaua4ube4juR"
   },
   "outputs": [],
   "source": [
    "y_axis_f = []\n",
    "mn = np.min(episodes_per_run)\n",
    "for i in range(mn):\n",
    "  total = 0\n",
    "  for j in rewards_avg:\n",
    "    total += j[i]\n",
    "  y_axis_f.append(total)\n",
    "\n",
    "plt.plot(np.arange(mn),y_axis_f)\n",
    "plt.xlabel('Rewards')\n",
    "plt.ylabel('Episodes')\n",
    "plt.savefig(fname = 'acrobot_ avg 4', format = 'jpeg')\n",
    "plt.show()\n",
    "\n",
    "print('Avg number of episodes req = {}'.format(np.mean(episodes_per_run)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R_hXk1tS4luq"
   },
   "outputs": [],
   "source": [
    "np.save('acrobot4_arr', actual_rewards)\n",
    "\n",
    "arr = np.load('acrobot4_arr.npy',allow_pickle=True)\n",
    "print('for acrobot_4')\n",
    "cnt = 0\n",
    "for rewards in arr:\n",
    "  cnt = cnt + 1\n",
    "  print('Taking running avg of 100')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-99)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 100')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_4 run {} 100 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_4 run {} 100 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 10')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-9)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_4 run {} 10 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_4 run {} 10 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 1')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_4 run {} 1 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_4 run {} 1 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yWo5Xkk4nn9"
   },
   "outputs": [],
   "source": [
    "env2 = gym.make('Acrobot-v1')\n",
    "episodes_per_run =[]\n",
    "steps = []\n",
    "rewards_avg = []\n",
    "actual_rewards = []\n",
    "\n",
    "for i1 in range(10):\n",
    "  steps1 = []\n",
    "  plt.xlabel('Episodes')\n",
    "  plt.ylabel('Average_score')\n",
    "  [scores, num_episodes, steps_per_episode] = dqn(env2, exploration = 'epsilon',learning_rate = 0.005, hyp_start = 1, hyp_decay = 0.995,hyp_end = 0.001,update_freq = 75, buffer_size = int(2e5),batch_size = 128)\n",
    "  episodes_per_run.append(num_episodes)\n",
    "  actual_rewards.append(scores)\n",
    "  steps.append(steps_per_episode)\n",
    "  y_axis = []\n",
    "  n_ep = len(scores)\n",
    "  for i in range(len(scores)):\n",
    "    idx = min(99,i)\n",
    "    y_axis.append(np.mean(scores[i-idx:i+1]))\n",
    "    \n",
    "  plt.plot(np.arange(len(y_axis)) ,y_axis)\n",
    "  rewards_avg.append(y_axis)\n",
    "\n",
    "  plt.savefig(fname = \"acrobot5 \" + \"run \" + str(i1),format = 'jpeg')\n",
    "  #steps.append(steps1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIF1zLJF4qGb"
   },
   "outputs": [],
   "source": [
    "y_axis_f = []\n",
    "mn = np.min(episodes_per_run)\n",
    "for i in range(mn):\n",
    "  total = 0\n",
    "  for j in rewards_avg:\n",
    "    total += j[i]\n",
    "  y_axis_f.append(total)\n",
    "\n",
    "plt.plot(np.arange(mn),y_axis_f)\n",
    "plt.xlabel('Rewards')\n",
    "plt.ylabel('Episodes')\n",
    "plt.savefig(fname = 'acrobot_ avg 5', format = 'jpeg')\n",
    "plt.show()\n",
    "\n",
    "print('Avg number of episodes req = {}'.format(np.mean(episodes_per_run)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMoc7gRW4sTH"
   },
   "outputs": [],
   "source": [
    "np.save('acrobot5_arr', actual_rewards)\n",
    "\n",
    "arr = np.load('acrobot5_arr.npy',allow_pickle=True)\n",
    "print('for acrobot_5')\n",
    "cnt = 0\n",
    "for rewards in arr:\n",
    "  cnt = cnt + 1\n",
    "  print('Taking running avg of 100')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-99)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 100')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_5 run {} 100 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_5 run {} 100 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 10')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-9)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_5 run {} 10 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_5 run {} 10 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 1')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('acrobot_5 run {} 1 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'acrobot_5 run {} 1 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9SCSFWc4xyr"
   },
   "source": [
    "#CartPole\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bO159t841FH"
   },
   "outputs": [],
   "source": [
    "env2 = gym.make('CartPole-v1')\n",
    "episodes_per_run =[]\n",
    "steps = []\n",
    "rewards_avg = []\n",
    "actual_rewards = []\n",
    "\n",
    "\n",
    "for i1 in range(10):\n",
    "  steps1 = []\n",
    "  plt.xlabel('Episodes')\n",
    "  plt.ylabel('Average_score')\n",
    "  [scores, num_episodes, steps_per_episode] = dqn(env2 , learning_rate = 0.0005,update_freq = 25, buffer_size = int(1e5),batch_size = 64)\n",
    "  episodes_per_run.append(num_episodes)\n",
    "  actual_rewards.append(scores)\n",
    "  steps.append(steps_per_episode)\n",
    "  y_axis = []\n",
    "  n_ep = len(scores)\n",
    "  for i in range(len(scores)):\n",
    "    idx = min(99,i)\n",
    "    y_axis.append(np.mean(scores[i-idx:i+1]))\n",
    "    \n",
    "  plt.plot(np.arange(len(y_axis)) ,y_axis)\n",
    "  rewards_avg.append(y_axis)\n",
    "\n",
    "  plt.savefig(fname = \"Cartpole config\" + \"3\" + str(i1),format = 'jpeg')\n",
    "  #steps.append(steps1)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DXvdrqi74_kN"
   },
   "outputs": [],
   "source": [
    "y_axis_f = []\n",
    "mn = np.min(episodes_per_run)\n",
    "for i in range(mn):\n",
    "  total = 0\n",
    "  for j in rewards_avg:\n",
    "    total += j[i]\n",
    "  y_axis_f.append(total)\n",
    "\n",
    "plt.plot(np.arange(mn),y_axis_f)\n",
    "plt.xlabel('Rewards')\n",
    "plt.ylabel('Episodes')\n",
    "plt.savefig(fname = 'acrofinal 4', format = 'jpeg')\n",
    "plt.show()\n",
    "\n",
    "print('Avg number of episodes req = {}'.format(np.mean(episodes_per_run)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I-5u2HNR5CGt"
   },
   "outputs": [],
   "source": [
    "#save the array of rewards\n",
    "np.save('cartpole1_arr', actual_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rd52WzRg5Drz"
   },
   "outputs": [],
   "source": [
    "arr = np.load('cartpole1_arr.npy',allow_pickle=True)\n",
    "print('for cartpole_1')\n",
    "cnt = 0\n",
    "for rewards in arr:\n",
    "  cnt = cnt + 1\n",
    "  print('Taking running avg of 100')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-99)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 100')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('cartpole_1 run {} 100 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'cartpole_1 run {} 100 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 10')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i-9)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('cartpole_1 run {} 10 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'cartpole_1 run {} 10 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n",
    "\n",
    "  print('Taking running avg of 1')\n",
    "  y_axis = []\n",
    "  for i in range(len(rewards)):\n",
    "    idx = max(0,i)\n",
    "    y_axis.append(np.mean(rewards[idx:i+1]))\n",
    "\n",
    "  plt.ylabel('rewards avg 10')\n",
    "  plt.xlabel('episodes')\n",
    "  plt.title('cartpole_1 run {} 1 avg'.format(cnt))\n",
    "  plt.plot(np.arange(len(rewards)),y_axis)\n",
    "  plt.savefig(fname = 'cartpole_1 run {} 1 avg'.format(cnt) , format = 'jpeg')\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0LNO9ZM__Hu"
   },
   "source": [
    "#### Actor Critic Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28p50voY-y_A"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Installing packages for rendering the game on Colab\n",
    "'''\n",
    "\n",
    "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
    "!apt-get update > /dev/null 2>&1\n",
    "!apt-get install cmake > /dev/null 2>&1\n",
    "!pip install --upgrade setuptools 2>&1\n",
    "!pip install ez_setup > /dev/null 2>&1\n",
    "!pip install gym[atari] > /dev/null 2>&1\n",
    "!pip install git+https://github.com/tensorflow/docs > /dev/null 2>&1\n",
    "!pip install gym\n",
    "!pip install pyglet\n",
    "# Install additional packages for visualization\n",
    "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
    "!pip install pyvirtualdisplay > /dev/null 2>&1\n",
    "!pip install git+https://github.com/tensorflow/docs > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnfjsYE1-y2I"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "A bunch of imports, you don't have to worry about these\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn  \n",
    "import torch.nn.functional as F\n",
    "from collections import namedtuple, deque\n",
    "import torch.optim as optim\n",
    "import datetime\n",
    "import gym\n",
    "from gym.wrappers import Monitor\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from pyvirtualdisplay import Display\n",
    "import tensorflow as tf\n",
    "from IPython import display as ipythondisplay\n",
    "from PIL import Image\n",
    "import tensorflow_probability as tfp\n",
    "import collections\n",
    "import gym\n",
    "import numpy as np\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from typing import Any, List, Sequence, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Vac4yEA-yud"
   },
   "outputs": [],
   "source": [
    "# Set seed for experiment reproducibility\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "# Small epsilon value for stabilizing division operations\n",
    "eps = np.finfo(np.float32).eps.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrVl8ZWY-ylh"
   },
   "outputs": [],
   "source": [
    "class ActorCriticModel(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Defining policy and value networkss\n",
    "    \"\"\"\n",
    "    def __init__(self, action_size, n_hidden1=128, n_hidden2=256, temp=1.0):\n",
    "        super(ActorCriticModel, self).__init__()\n",
    "\n",
    "        #Hidden Layer 1\n",
    "        self.fc1 = tf.keras.layers.Dense(n_hidden1, activation='relu')\n",
    "        #Hidden Layer 2\n",
    "        self.fc2 = tf.keras.layers.Dense(n_hidden2, activation='relu')\n",
    "        \n",
    "        #Output Layer for policy\n",
    "        self.pi_out = tf.keras.layers.Dense(action_size, activation='softmax')\n",
    "        #Output Layer for state-value\n",
    "        self.v_out = tf.keras.layers.Dense(1)\n",
    "        self.temp = temp\n",
    "\n",
    "    def call(self, state):\n",
    "        \"\"\"\n",
    "        Computes policy distribution and state-value for a given state\n",
    "        \"\"\"\n",
    "        layer1 = self.fc1(state)\n",
    "        layer2 = self.fc2(layer1)\n",
    "\n",
    "        pi = self.pi_out(layer2)\n",
    "        v = self.v_out(layer2)\n",
    "        return pi/self.temp, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "raEkQNFP-ydY"
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"\n",
    "    Agent class\n",
    "    \"\"\"\n",
    "    def __init__(self, action_size, lr=0.001, gamma=0.99, n_hidden1=128, n_hidden2=256, temp=1, seed = 85):\n",
    "        self.gamma = gamma\n",
    "        self.ac_model = ActorCriticModel(action_size, n_hidden1, n_hidden2, temp=temp)\n",
    "        self.ac_model.compile(tf.keras.optimizers.Adam(learning_rate=lr))\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def sample_action(self, state):\n",
    "        \"\"\"\n",
    "        Given a state, compute the policy distribution over all actions and sample one action\n",
    "        \"\"\"\n",
    "        pi,_ = self.ac_model(state)\n",
    "\n",
    "        action_probabilities = tfp.distributions.Categorical(probs=pi)\n",
    "        sample = action_probabilities.sample()\n",
    "\n",
    "        return int(sample.numpy()[0])\n",
    "\n",
    "    def actor_loss(self, action, pi, delta):\n",
    "        \"\"\"\n",
    "        Compute Actor Loss\n",
    "        \"\"\"\n",
    "        return -tf.math.log(pi[0,action]) * delta\n",
    "\n",
    "    def critic_loss(self,delta):\n",
    "        \"\"\"\n",
    "        Critic loss aims to minimize TD error\n",
    "        \"\"\"\n",
    "        return delta**2\n",
    "\n",
    "    \n",
    "    def learn(self, state, action, reward, next_state, done):\n",
    "        \"\"\"\n",
    "        For a given transition (s,a,s',r) update the paramters by computing the\n",
    "        gradient of the total loss\n",
    "        \"\"\"\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            pi, V_s = self.ac_model(state)\n",
    "            _, V_s_next = self.ac_model(next_state)\n",
    "            \n",
    "            V_s = tf.squeeze(V_s)\n",
    "            V_s_next = tf.squeeze(V_s_next)\n",
    "            \n",
    "\n",
    "            #### TO DO: Write the equation for delta (TD error)\n",
    "            ## Write code below\n",
    "            delta = reward + self.gamma*V_s_next - V_s\n",
    "\n",
    "            loss_a = self.actor_loss(action, pi, delta)\n",
    "            loss_c =self.critic_loss(delta)\n",
    "            loss_total = loss_a + loss_c\n",
    "\n",
    "        gradient = tape.gradient(loss_total, self.ac_model.trainable_variables)\n",
    "        self.ac_model.optimizer.apply_gradients(zip(gradient, self.ac_model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4BTUIIwv-yWQ"
   },
   "outputs": [],
   "source": [
    "def save_plots_and_arrays1(environment, nstep, all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, config=1, num_exp=10):\n",
    "    min_episodes = min(num_episodes_taken)\n",
    "    avg1 = np.zeros(shape=(num_exp, min_episodes))\n",
    "    avg2 = np.zeros(shape=(num_exp, min_episodes))\n",
    "    avg3 = np.zeros(shape=(num_exp, min_episodes))\n",
    "    for exp in range(num_exp):\n",
    "        avg_rewards_1 = np.array(all_avg_rewards_1[exp])\n",
    "        avg_rewards_2 = np.array(all_avg_rewards_1[exp])\n",
    "        avg_rewards_3 = np.array(all_avg_rewards_1[exp])\n",
    "        avg1[exp] = avg_rewards_1[:min_episodes]\n",
    "        avg2[exp] = avg_rewards_2[:min_episodes]\n",
    "        avg3[exp] = avg_rewards_3[:min_episodes]\n",
    "        episodes = avg_rewards_1.shape[0]\n",
    "        np.save('{}_{}_{}_{}_1'.format(environment, nstep, config, exp), avg_rewards_1)\n",
    "        np.save('{}_{}_{}_{}_2'.format(environment, nstep, config, exp), avg_rewards_2)\n",
    "        np.save('{}_{}_{}_{}_3'.format(environment, nstep, config, exp), avg_rewards_3)\n",
    "        print(np.std(avg_rewards_1), np.std(avg_rewards_2), np.std(avg_rewards_3))\n",
    "        plt.figure(figsize = (6, 4))\n",
    "        plt.plot(np.arange(0, episodes), avg_rewards_1)\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Average Rewards')\n",
    "        plt.savefig('{}_{}_{}_{}_1'.format(environment, nstep, config, exp))\n",
    "        plt.figure(figsize = (6, 4))\n",
    "        plt.plot(np.arange(0, episodes), avg_rewards_2)\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Average Rewards')\n",
    "        plt.savefig('{}_{}_{}_{}_2'.format(environment, nstep, config, exp))\n",
    "        plt.figure(figsize = (6, 4))\n",
    "        plt.plot(np.arange(0, episodes), avg_rewards_3)\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Average Rewards')\n",
    "        plt.savefig('{}_{}_{}_{}_3'.format(environment, nstep, config, exp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j7Sqnd5w-yOl"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def Actor_Critic_run_1(env, num_experiments=10, max_episodes = 5000, max_steps_per_episode = 1000, temp=0.1, decay=0.99, nstep=1000, gamma=0.99, n_hidden1=128, n_hidden2=256, reward_threshold=-100, lr=0.01):\n",
    "\n",
    "    all_avg_rewards_1 = []\n",
    "    all_avg_rewards_2 = []\n",
    "    all_avg_rewards_3 = []\n",
    "    num_episodes_taken = []\n",
    "    agents = []\n",
    "\n",
    "    for i in range(num_experiments):\n",
    "        #Initializing Agent\n",
    "        agent = Agent(lr=lr, action_size=env.action_space.n, gamma=gamma, n_hidden1=128, n_hidden2=256, temp=temp)\n",
    "        #Number of episodes\n",
    "        episodes = max_episodes\n",
    "        tf.compat.v1.reset_default_graph()\n",
    "        episodes_reward: collections.deque = collections.deque(maxlen=100)\n",
    "        avg_reward: collections.deque = collections.deque(maxlen=10)\n",
    "        reward_list = []\n",
    "        average_reward_list = []\n",
    "        begin_time = datetime.datetime.now()\n",
    "        avg_rewards_1 = []\n",
    "        avg_rewards_2 = []\n",
    "        avg_rewards_3 = []\n",
    "        f = tf.function(agent.learn)\n",
    "        num = 0\n",
    "        for ep in range(1, episodes + 1):\n",
    "            state = env.reset().reshape(1,-1)\n",
    "            done = False\n",
    "            ep_rew = 0\n",
    "            while not done:\n",
    "                action = agent.sample_action(state) ##Sample Action\n",
    "                next_state, reward, done, info = env.step(action) ##Take action\n",
    "                next_state = next_state.reshape(1,-1)\n",
    "                ep_rew += reward  ##Updating episode reward\n",
    "                f(state, action, reward, next_state, done) ##Update Parameters\n",
    "                state = next_state ##Updating State\n",
    "            avg_reward.append(ep_rew)\n",
    "            episodes_reward.append(ep_rew)\n",
    "            reward_list.append(ep_rew)\n",
    "            avg_rewards_1.append(ep_rew)\n",
    "            avg_rewards_2.append(statistics.mean(avg_reward))\n",
    "            avg_rewards_3.append(statistics.mean(episodes_reward))\n",
    "            num += 1\n",
    "            if ep % 10 == 0:\n",
    "                avg_rew = np.mean(reward_list[-10:])\n",
    "                print('Episode ', ep, 'Reward %f' % ep_rew, 'Average Reward %f' % np.mean(reward_list[-100:]))\n",
    "\n",
    "            if ep % 100:\n",
    "                avg_100 =  np.mean(reward_list[-100:])\n",
    "                if avg_100 > reward_threshold:\n",
    "                    print('Stopped at Episode ',ep)\n",
    "                    break\n",
    "        all_avg_rewards_1.append(avg_rewards_1)\n",
    "        all_avg_rewards_2.append(avg_rewards_2)\n",
    "        all_avg_rewards_3.append(avg_rewards_3)\n",
    "        agents.append(agent)\n",
    "        num_episodes_taken.append(num)\n",
    "    return all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, agents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dy-gzxftAHBi"
   },
   "source": [
    "### One step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTJoBi1sAMU_"
   },
   "source": [
    "### Acrobot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xphnra8f-yJZ"
   },
   "outputs": [],
   "source": [
    "environment = 'Acrobot-v1'\n",
    "env = gym.make('Acrobot-v1')\n",
    "num_experiments = 10\n",
    "max_episodes = 5000\n",
    "reward_threshold = -100\n",
    "nstep = 1\n",
    "temp = 1\n",
    "gamma = 0.99\n",
    "n_hidden1 = 128\n",
    "n_hidden2 = 256\n",
    "lr = 0.01\n",
    "all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, agents = Actor_Critic_run_1(env=env, num_experiments=num_experiments, max_episodes = max_episodes, max_steps_per_episode = 10, temp=temp, decay=0.99, nstep=nstep, gamma=gamma, n_hidden1=n_hidden1, n_hidden2=n_hidden2, reward_threshold=reward_threshold, lr=lr)\n",
    "save_plots_and_arrays1(environment, nstep, all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, config=1, num_exp=num_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llDGqCmSAP95"
   },
   "source": [
    "### Cartpole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CLwEEMUh-yEL"
   },
   "outputs": [],
   "source": [
    "environment = 'CartPole-v1'\n",
    "env = gym.make('CartPole-v1')\n",
    "num_experiments = 10\n",
    "max_episodes = 5000\n",
    "reward_threshold = 230\n",
    "nstep = 1\n",
    "temp = 1\n",
    "gamma = 0.99\n",
    "n_hidden1 = 128\n",
    "n_hidden2 = 256\n",
    "lr = 0.01\n",
    "all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, agents = Actor_Critic_run_1(env=env, num_experiments=num_experiments, max_episodes = max_episodes, max_steps_per_episode = 10, temp=temp, decay=0.99, nstep=nstep, gamma=gamma, n_hidden1=n_hidden1, n_hidden2=n_hidden2, reward_threshold=reward_threshold, lr=lr)\n",
    "save_plots_and_arrays1(environment, nstep, all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, config=1, num_exp=num_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fZHhPiiAVmy"
   },
   "source": [
    "### Mountain Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gV12cYka-x-9"
   },
   "outputs": [],
   "source": [
    "environment = 'MountainCar-v0'\n",
    "env = gym.make('MountainCar-v0')\n",
    "num_experiments = 10\n",
    "max_episodes = 5000\n",
    "reward_threshold = -110\n",
    "nstep = 1\n",
    "temp = 1\n",
    "gamma = 0.99\n",
    "n_hidden1 = 128\n",
    "n_hidden2 = 256\n",
    "lr = 0.01\n",
    "all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, agents = Actor_Critic_run_1(env=env, num_experiments=num_experiments, max_episodes = max_episodes, max_steps_per_episode = 10, temp=temp, decay=0.99, nstep=nstep, gamma=gamma, n_hidden1=n_hidden1, n_hidden2=n_hidden2, reward_threshold=reward_threshold, lr=lr)\n",
    "save_plots_and_arrays1(environment, nstep, all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, config=1, num_exp=num_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rBm4dCzEAaAh"
   },
   "source": [
    "## n step and Full returns.\n",
    "set nstep = 1000 for full returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJ82YlxG-x5v"
   },
   "outputs": [],
   "source": [
    "class ActorCritic(tf.keras.Model):\n",
    "  \"\"\" Separate Actor-critic network.\"\"\"\n",
    "\n",
    "  def __init__(\n",
    "      self, \n",
    "      num_actions: int,\n",
    "      actor_units1: int, \n",
    "      actor_units2: int, \n",
    "      critic_units1: int, \n",
    "      critic_units2: int):\n",
    "    \"\"\"Initialize.\"\"\"\n",
    "    super().__init__()\n",
    "    self.actor_layer1 = layers.Dense(actor_units1, activation=\"relu\")\n",
    "    self.actor_layer2 = layers.Dense(actor_units2, activation=\"relu\")\n",
    "    self.actor = layers.Dense(num_actions)\n",
    "    self.critic_layer1 = layers.Dense(critic_units1, activation=\"relu\")\n",
    "    self.critic_layer2 = layers.Dense(critic_units2, activation=\"relu\")\n",
    "    self.critic = layers.Dense(1)\n",
    "\n",
    "  def call(self, inputs: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    x = self.actor_layer1(inputs)\n",
    "    x = self.actor_layer2(x)\n",
    "    y = self.critic_layer1(inputs)\n",
    "    y = self.critic_layer2(y)\n",
    "    return self.actor(x), self.critic(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZS0uNZH9-x0P"
   },
   "outputs": [],
   "source": [
    "# Wrap OpenAI Gym's `env.step` call as an operation in a TensorFlow function.\n",
    "# This would allow it to be included in a callable TensorFlow graph.\n",
    "\n",
    "def env_step(action: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "  \"\"\"Returns state, reward and done flag given an action.\"\"\"\n",
    "\n",
    "  state, reward, done, _ = env.step(action)\n",
    "  return (state.astype(np.float32), \n",
    "          np.array(reward, np.int32), \n",
    "          np.array(done, np.int32))\n",
    "\n",
    "\n",
    "def tf_env_step(action: tf.Tensor) -> List[tf.Tensor]:\n",
    "  return tf.numpy_function(env_step, [action], \n",
    "                           [tf.float32, tf.int32, tf.int32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krLHGLFL-xrT"
   },
   "outputs": [],
   "source": [
    "def run_episode(\n",
    "    initial_state: tf.Tensor,  \n",
    "    model: tf.keras.Model, \n",
    "    max_steps: int,\n",
    "    temp: int) -> Tuple[tf.Tensor, tf.Tensor, tf.Tensor, int]:\n",
    "  \"\"\"Runs a single episode to collect training data.\"\"\"\n",
    "\n",
    "  action_probs = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "  values = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)\n",
    "  rewards = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "  t = tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "  initial_state_shape = initial_state.shape\n",
    "  state = initial_state\n",
    "  steps = 0\n",
    "\n",
    "  for t in tf.range(max_steps):\n",
    "    # Convert state into a batched tensor (batch size = 1)\n",
    "    state = tf.expand_dims(state, 0)\n",
    "\n",
    "    # Run the model and to get action probabilities and critic value\n",
    "    action_logits_t, value = model(state)\n",
    "    action_logits_t = action_logits_t/temp\n",
    "    # Sample next action from the action probability distribution\n",
    "    action = tf.random.categorical(action_logits_t, 1)[0, 0]\n",
    "    action_probs_t = tf.nn.softmax(action_logits_t)\n",
    "\n",
    "    # Store critic values\n",
    "    values = values.write(t, tf.squeeze(value))\n",
    "\n",
    "    # Store log probability of the action chosen\n",
    "    action_probs = action_probs.write(t, action_probs_t[0, action])\n",
    "\n",
    "    # Apply action to the environment to get next state and reward\n",
    "    state, reward, done = tf_env_step(action)\n",
    "    state.set_shape(initial_state_shape)\n",
    "\n",
    "    # Store reward\n",
    "    rewards = rewards.write(t, reward)\n",
    "    steps = steps + 1\n",
    "\n",
    "    if tf.cast(done, tf.bool):\n",
    "      break\n",
    "\n",
    "  action_probs = action_probs.stack()\n",
    "  values = values.stack()\n",
    "  rewards = rewards.stack()\n",
    "\n",
    "  return action_probs, values, rewards, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yelacnhp-xgz"
   },
   "outputs": [],
   "source": [
    "# Finds n step return for any time step. Set n=1000 for full return.\n",
    "\n",
    "def get_expected_return(\n",
    "    rewards: tf.Tensor,\n",
    "    values: tf.Tensor, \n",
    "    gamma: float,\n",
    "    nstep: int,\n",
    "    standardize: bool = True) -> tf.Tensor:\n",
    "  \"\"\"Compute n step return per timestep.\"\"\"\n",
    "\n",
    "\n",
    "  a = pow(gamma, nstep)\n",
    "  b = pow(gamma, nstep-1)\n",
    "  n = tf.shape(rewards)[0]\n",
    "  returns = tf.TensorArray(dtype=tf.float32, size=n)\n",
    "  rewards = tf.cast(rewards, dtype=tf.float32)\n",
    "  discounted_sum = tf.constant(0.0)\n",
    "  discounted_sum_shape = discounted_sum.shape\n",
    "  if nstep == 1000:   \n",
    "      nstep = n\n",
    "  for i in tf.range(n-1, -1, -1):\n",
    "    reward = rewards[i]\n",
    "    if i+nstep >= n:\n",
    "        discounted_sum = reward + gamma * discounted_sum\n",
    "    else:\n",
    "        discounted_sum = reward + gamma * discounted_sum + a*values[i+nstep]\n",
    "    \n",
    "    discounted_sum.set_shape(discounted_sum_shape)\n",
    "    returns = returns.write(i, discounted_sum)\n",
    "    if i+nstep < n:\n",
    "        discounted_sum -= a*values[i+nstep]\n",
    "    if i+nstep-1 < n:\n",
    "        discounted_sum -= b*rewards[i+nstep-1]\n",
    "    discounted_sum.set_shape(discounted_sum_shape)\n",
    "\n",
    "  returns = returns.stack()\n",
    "  if standardize:\n",
    "    returns = ((returns - tf.math.reduce_mean(returns)) / \n",
    "               (tf.math.reduce_std(returns) + eps))\n",
    "  \n",
    "  return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLZTCBCR-xUi"
   },
   "outputs": [],
   "source": [
    "mse_loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n",
    "\n",
    "def compute_loss(\n",
    "    action_probs: tf.Tensor,  \n",
    "    values: tf.Tensor,  \n",
    "    returns: tf.Tensor) -> tf.Tensor:\n",
    "  \"\"\"Computes the combined actor-critic loss.\"\"\"\n",
    "\n",
    "  advantage = returns - values\n",
    "\n",
    "  action_log_probs = tf.math.log(action_probs)\n",
    "  actor_loss = -tf.math.reduce_sum(action_log_probs * advantage)\n",
    "\n",
    "  critic_loss = mse_loss(values, returns)\n",
    "\n",
    "  return actor_loss + critic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEdJadbP_SQX"
   },
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    initial_state: tf.Tensor, \n",
    "    model: tf.keras.Model, \n",
    "    optimizer: tf.keras.optimizers.Optimizer, \n",
    "    gamma: float, \n",
    "    max_steps_per_episode: int,\n",
    "    nstep: int,\n",
    "    temp: int) -> Tuple[tf.Tensor, int]:\n",
    "  \"\"\"Runs a model training step.\"\"\"\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    # Run the model for one episode to collect training data\n",
    "    action_probs, values, rewards, steps = run_episode(\n",
    "        initial_state, model, max_steps_per_episode, temp) \n",
    "\n",
    "    # Calculate expected returns\n",
    "    returns = get_expected_return(rewards, values, gamma, nstep)\n",
    "    # return rewards, values, returns\n",
    "    #returns = get_expected_return1(rewards, gamma)\n",
    "\n",
    "    # Convert training data to appropriate TF tensor shapes\n",
    "    action_probs, values, returns = [\n",
    "        tf.expand_dims(x, 1) for x in [action_probs, values, returns]] \n",
    "\n",
    "    # Calculating loss values to update our network\n",
    "    loss = compute_loss(action_probs, values, returns)\n",
    "\n",
    "  # Compute the gradients from the loss\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "  # Apply the gradients to the model's parameters\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  episode_reward = tf.math.reduce_sum(rewards)\n",
    "\n",
    "  return episode_reward, steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RflfyIhP_SF_"
   },
   "outputs": [],
   "source": [
    "def save_plots_and_arrays2(environment, nstep, all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, config=1, num_exp=10):\n",
    "    min_episodes = min(num_episodes_taken)\n",
    "    avg1 = np.zeros(shape=(num_exp, min_episodes))\n",
    "    avg2 = np.zeros(shape=(num_exp, min_episodes))\n",
    "    avg3 = np.zeros(shape=(num_exp, min_episodes))\n",
    "    for exp in range(num_exp):\n",
    "        avg_rewards_1 = np.array(all_avg_rewards_1[exp])\n",
    "        avg_rewards_2 = np.array(all_avg_rewards_1[exp])\n",
    "        avg_rewards_3 = np.array(all_avg_rewards_1[exp])\n",
    "        avg1[exp] = avg_rewards_1[:min_episodes]\n",
    "        avg2[exp] = avg_rewards_2[:min_episodes]\n",
    "        avg3[exp] = avg_rewards_3[:min_episodes]\n",
    "        episodes = avg_rewards_1.shape[0]\n",
    "        np.save('{}_{}_{}_{}_1'.format(environment, nstep, config, exp), avg_rewards_1)\n",
    "        np.save('{}_{}_{}_{}_2'.format(environment, nstep, config, exp), avg_rewards_2)\n",
    "        np.save('{}_{}_{}_{}_3'.format(environment, nstep, config, exp), avg_rewards_3)\n",
    "        print(np.std(avg_rewards_1), np.std(avg_rewards_2), np.std(avg_rewards_3))\n",
    "        plt.figure(figsize = (6, 4))\n",
    "        plt.plot(np.arange(0, episodes), avg_rewards_1)\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Average Rewards')\n",
    "        plt.savefig('{}_{}_{}_{}_1'.format(environment, nstep, config, exp))\n",
    "        plt.figure(figsize = (6, 4))\n",
    "        plt.plot(np.arange(0, episodes), avg_rewards_2)\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Average Rewards')\n",
    "        plt.savefig('{}_{}_{}_{}_2'.format(environment, nstep, config, exp))\n",
    "        plt.figure(figsize = (6, 4))\n",
    "        plt.plot(np.arange(0, episodes), avg_rewards_3)\n",
    "        plt.xlabel('Episodes')\n",
    "        plt.ylabel('Average Rewards')\n",
    "        plt.savefig('{}_{}_{}_{}_3'.format(environment, nstep, config, exp))\n",
    "    print(np.mean(np.std(avg1, axis=0)), np.mean(np.std(avg2, axis=0)), np.mean(np.std(avg3, axis=0)))\n",
    "    episodes = min_episodes\n",
    "    plt.figure(figsize = (6, 4))\n",
    "    plt.plot(np.arange(0, episodes), np.std(avg1, axis=0))\n",
    "    plt.title('{} step'.format(nstep))\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Standard deviation')\n",
    "    plt.savefig('{}_{}_{}_{}_1_std'.format(environment, nstep, config, 1))\n",
    "    plt.figure(figsize = (6, 4))\n",
    "    plt.plot(np.arange(0, episodes), np.std(avg2, axis=0))\n",
    "    plt.title('{} step'.format(nstep))\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Standard deviation')\n",
    "    plt.savefig('{}_{}_{}_{}_2_std'.format(environment, nstep, config, 1))\n",
    "    plt.figure(figsize = (6, 4))\n",
    "    plt.plot(np.arange(0, episodes), np.std(avg3, axis=0))\n",
    "    plt.title('{} step'.format(nstep))\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Standard Deviation')\n",
    "    plt.savefig('{}_{}_{}_{}_3_std'.format(environment, nstep, config, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q8YNyvhK_R75"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def Actor_Critic_run_2(num_experiments=10, max_episodes = 5000, max_steps_per_episode = 1000, temp=0.1, decay=0.99, nstep=1000, gamma=0.99, actor_units1=128, actor_units2=128, critic_units1=128, critic_units2=128, reward_threshold=-100, lr=0.01):\n",
    "    all_avg_rewards_1 = []\n",
    "    all_avg_rewards_2 = []\n",
    "    all_avg_rewards_3 = []\n",
    "    num_episodes_taken = []\n",
    "    models = []\n",
    "    for k in range(num_experiments):\n",
    "        num_actions = env.action_space.n  # 2\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        model = ActorCritic(num_actions, actor_units1, actor_units2, critic_units1, critic_units2)\n",
    "        min_episodes_criterion = 100\n",
    "        avg_criterion_2 = 10\n",
    "        running_reward = 0\n",
    "        # Keep last episodes reward\n",
    "        episodes_reward: collections.deque = collections.deque(maxlen=100)\n",
    "        avg_reward: collections.deque = collections.deque(maxlen=10)\n",
    "        avg_rewards_1 = []\n",
    "        avg_rewards_2 = []\n",
    "        avg_rewards_3 = []\n",
    "        f = tf.function(train_step)\n",
    "        with tqdm.trange(max_episodes) as t:\n",
    "            for i in t:\n",
    "                initial_state = tf.constant(env.reset(), dtype=tf.float32)\n",
    "                episode_reward, episode_steps = f(\n",
    "                    initial_state, model, optimizer, gamma, max_steps_per_episode, nstep, temp)\n",
    "                episode_reward = int(episode_reward)\n",
    "                episodes_reward.append(episode_reward)\n",
    "                avg_reward.append(episode_reward)\n",
    "                running_reward = statistics.mean(episodes_reward)\n",
    "                avg_rewards_1.append(episode_reward)\n",
    "                avg_rewards_2.append(statistics.mean(avg_reward))\n",
    "                avg_rewards_3.append(running_reward)\n",
    "                t.set_description(f'Episode {i}')\n",
    "                t.set_postfix(\n",
    "                    episode_reward=episode_reward, running_reward=running_reward)\n",
    "\n",
    "                # Show average episode reward every 10 episodes\n",
    "                if i % 10 == 0:\n",
    "                    pass # print(f'Episode {i}: average reward: {avg_reward}')\n",
    "\n",
    "                if running_reward > reward_threshold and i >= min_episodes_criterion:  \n",
    "                    break\n",
    "        all_avg_rewards_1.append(avg_rewards_1)\n",
    "        all_avg_rewards_2.append(avg_rewards_2)\n",
    "        all_avg_rewards_3.append(avg_rewards_3)\n",
    "        num_episodes_taken.append(len(avg_rewards_1))\n",
    "        models.append(model)\n",
    "        print(f'\\nSolved at episode {i+1}: average reward: {running_reward:.2f}!')\n",
    "    return all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7w8F4jiAke2"
   },
   "source": [
    "### Acrobot 10 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BemWUh_-_RyJ"
   },
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\"Acrobot-v1\")\n",
    "env.seed(seed)\n",
    "reward_threshold = -90\n",
    "environment = \"Acrobot-v1\"\n",
    "nstep = 10\n",
    "max_episodes = 5000\n",
    "max_steps_per_episode = 1000\n",
    "num_experiments = 10\n",
    "temp = 1\n",
    "decay = 0.99\n",
    "gamma = 0.99\n",
    "actor_units1 = 128\n",
    "actor_units2 =256\n",
    "critic_units1 =128\n",
    "critic_units2 =256\n",
    "lr = 0.001\n",
    "all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, models = Actor_Critic_run_2(num_experiments, max_episodes, max_steps_per_episode, temp, decay, nstep, gamma, actor_units1, actor_units2, critic_units1, critic_units2, reward_threshold, lr)\n",
    "save_plots_and_arrays2(environment, nstep, all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, num_exp=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9xWFJAdAqR9"
   },
   "source": [
    "### Acrobot full step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "posIgGqB_Rnu"
   },
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\"Acrobot-v1\")\n",
    "env.seed(seed)\n",
    "reward_threshold = -90\n",
    "environment = \"Acrobot-v1\"\n",
    "nstep = 1000\n",
    "max_episodes = 5000\n",
    "max_steps_per_episode = 1000\n",
    "num_experiments = 10\n",
    "temp = 1\n",
    "decay = 0.99\n",
    "gamma = 0.99\n",
    "actor_units1 = 128\n",
    "actor_units2 =256\n",
    "critic_units1 =128\n",
    "critic_units2 =256\n",
    "lr = 0.001\n",
    "all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, models = Actor_Critic_run_2(num_experiments, max_episodes, max_steps_per_episode, temp, decay, nstep, gamma, actor_units1, actor_units2, critic_units1, critic_units2, reward_threshold, lr)\n",
    "save_plots_and_arrays2(environment, nstep, all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, num_exp=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgNjyuQWAths"
   },
   "source": [
    "### Cartpole 10 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fPjWBjx_RcM"
   },
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "env.seed(seed)\n",
    "reward_threshold = 475\n",
    "environment = \"CartPole-v1\"\n",
    "nstep = 10\n",
    "max_episodes = 5000\n",
    "max_steps_per_episode = 1000\n",
    "num_experiments = 10\n",
    "temp = 1\n",
    "decay = 0.99\n",
    "gamma = 0.99\n",
    "actor_units1 = 128\n",
    "actor_units2 =256\n",
    "critic_units1 =128\n",
    "critic_units2 =256\n",
    "lr = 0.001\n",
    "all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, models = Actor_Critic_run_2(num_experiments, max_episodes, max_steps_per_episode, temp, decay, nstep, gamma, actor_units1, actor_units2, critic_units1, critic_units2, reward_threshold, lr)\n",
    "save_plots_and_arrays2(environment, nstep, all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, num_exp=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uvdwaaWAv0r"
   },
   "source": [
    "### Cartpole full step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjBp8UtN_kup"
   },
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "env.seed(seed)\n",
    "reward_threshold = 475\n",
    "environment = \"CartPole-v1\"\n",
    "nstep = 1000\n",
    "max_episodes = 5000\n",
    "max_steps_per_episode = 1000\n",
    "num_experiments = 10\n",
    "temp = 1\n",
    "decay = 0.99\n",
    "gamma = 0.99\n",
    "actor_units1 = 128\n",
    "actor_units2 =256\n",
    "critic_units1 =128\n",
    "critic_units2 =256\n",
    "lr = 0.001\n",
    "all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, models = Actor_Critic_run_2(num_experiments, max_episodes, max_steps_per_episode, temp, decay, nstep, gamma, actor_units1, actor_units2, critic_units1, critic_units2, reward_threshold, lr)\n",
    "save_plots_and_arrays2(environment, nstep, all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, num_exp=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um5ElNXKAzzs"
   },
   "source": [
    "### Moutain Car 10 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBKZondg_kj-"
   },
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\"MoutainCar-v0\")\n",
    "env.seed(seed)\n",
    "reward_threshold = -110\n",
    "environment = \"MountainCar-v0\"\n",
    "nstep = 10\n",
    "max_episodes = 5000\n",
    "max_steps_per_episode = 1000\n",
    "num_experiments = 10\n",
    "temp = 1\n",
    "decay = 0.99\n",
    "gamma = 0.99\n",
    "actor_units1 = 128\n",
    "actor_units2 =256\n",
    "critic_units1 =128\n",
    "critic_units2 =256\n",
    "lr = 0.001\n",
    "all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, models = Actor_Critic_run_2(num_experiments, max_episodes, max_steps_per_episode, temp, decay, nstep, gamma, actor_units1, actor_units2, critic_units1, critic_units2, reward_threshold, lr)\n",
    "save_plots_and_arrays2(environment, nstep, all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, num_exp=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ML0OIpUlA7yJ"
   },
   "source": [
    "### Moutain Car full step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_BlMnPA_kZB"
   },
   "outputs": [],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\"MoutainCar-v0\")\n",
    "env.seed(seed)\n",
    "reward_threshold = -110\n",
    "environment = \"MoutainCar-v0\"\n",
    "nstep = 1000\n",
    "max_episodes = 5000\n",
    "max_steps_per_episode = 1000\n",
    "num_experiments = 10\n",
    "temp = 1\n",
    "decay = 0.99\n",
    "gamma = 0.99\n",
    "actor_units1 = 128\n",
    "actor_units2 =256\n",
    "critic_units1 =128\n",
    "critic_units2 =256\n",
    "lr = 0.001\n",
    "all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, models = Actor_Critic_run_2(num_experiments, max_episodes, max_steps_per_episode, temp, decay, nstep, gamma, actor_units1, actor_units2, critic_units1, critic_units2, reward_threshold, lr)\n",
    "save_plots_and_arrays2(environment, nstep, all_avg_rewards_1, all_avg_rewards_2, all_avg_rewards_3, num_episodes_taken, num_exp=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAQDgwedA-de"
   },
   "source": [
    "### Code for rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxg5_1Sd_qsl"
   },
   "outputs": [],
   "source": [
    "# Render an episode and save as a GIF file\n",
    "\n",
    "from IPython import display as ipythondisplay\n",
    "from PIL import Image\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "\n",
    "display = Display(visible=0, size=(400, 300))\n",
    "display.start()\n",
    "\n",
    "\n",
    "def render_episode(env: gym.Env, model: tf.keras.Model, max_steps: int): \n",
    "  screen = env.render(mode='rgb_array')\n",
    "  im = Image.fromarray(screen)\n",
    "\n",
    "  images = [im]\n",
    "\n",
    "  state = tf.constant(env.reset(), dtype=tf.float32)\n",
    "  for i in range(1, max_steps + 1):\n",
    "    state = tf.expand_dims(state, 0)\n",
    "    action_probs, _ = model(state)\n",
    "    action = np.argmax(np.squeeze(action_probs))\n",
    "\n",
    "    state, _, done, _ = env.step(action)\n",
    "    state = tf.constant(state, dtype=tf.float32)\n",
    "\n",
    "    # Render screen every 10 steps\n",
    "    if i % 10 == 0:\n",
    "      screen = env.render(mode='rgb_array')\n",
    "      images.append(Image.fromarray(screen))\n",
    "\n",
    "    if done:\n",
    "      break\n",
    "\n",
    "  return images\n",
    "\n",
    "\n",
    "# Save GIF image\n",
    "model = models[0]\n",
    "images = render_episode(env, model, max_steps_per_episode)\n",
    "image_file = '{}.gif'.format(environment)\n",
    "# loop=0: loop forever, duration=1: play each frame for 1ms\n",
    "images[0].save(\n",
    "    image_file, save_all=True, append_images=images[1:], loop=0, duration=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hi2RV10C_qio"
   },
   "outputs": [],
   "source": [
    "import tensorflow_docs.vis.embed as embed\n",
    "embed.embed_file(image_file)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PA2_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
